{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyForestScan Documentation","text":"<p>Calculate Forest Structural Metrics from lidar point clouds in Python</p> <p></p>"},{"location":"#overview","title":"Overview","text":"<p>PyForestScan is a Python library designed for analyzing and visualizing forest structure using airborne 3D point cloud data. The library helps derive important forest metrics such as Canopy Height, Plant Area Index (PAI), Canopy Cover, Plant Area Density (PAD), and Foliage Height Diversity (FHD).</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Forest Metrics: Calculate and visualize key metrics like Canopy Height, PAI, PAD, and FHD.</li> <li>Large Point Cloud Support: Utilizes efficient data formats such as EPT for large point cloud processing.</li> <li>Visualization: Create 2D and 3D visualizations of forest structure and structural metrics</li> <li>Extensibility: Easily add custom filters and visualization techniques to suit your needs.</li> </ul>"},{"location":"#examples","title":"Examples","text":"<ul> <li>Getting Started: DTM and CHM</li> <li>Calculating Forest Metrics</li> <li>Working with Large Point Clouds</li> </ul>"},{"location":"benchmarks/","title":"Benchmarking","text":"<p>PyForestScan is designed for high performance and memory efficiency, ensuring it can handle large-scale point cloud datasets effectively. While no other Python libraries specifically calculate these forest structure metrics, there are alternatives in R, such as the<code>leafR</code> library (Almeida et al. 2021), that offer similar functionality.</p> <p>We provide a direct performance comparison between PyForestScan and<code>leafR</code> to demonstrate its efficiency. In both cases, we calculate Plant Area Index (PAI) (this is labelled as Leaf Area Index in the <code>leafR</code> library) on a LAS tile, repeating the process 100 times and plotting the results. The measured benchmarking is only done on the functions to calculate PAI/LAI. It does not include time taken to load the point cloud, etc.</p> <p>The benchmarks were conducted on a Mac with an Apple M3 Max processor (16 cores) and 128GB RAM.</p> <p></p>"},{"location":"benchmarks/#code-used","title":"Code Used","text":"<p>To calculate LAI in <code>leafR</code>, and compare these with the python code, we:</p> <pre><code># Install and load required packages\nif (!require(\"lidR\")) install.packages(\"lidR\")\nif (!require(\"raster\")) install.packages(\"raster\")\nif (!require(\"leafR\")) install.packages(\"leafR\")\n\nlibrary(lidR)\nlibrary(raster)\nlibrary(leafR)\n\nfile_path &lt;- \"example_data/20191126_5QKB020840_normalized.laz\"\nlas &lt;- readLAS(file_path)\nif (is.empty(las)) {\n  stop(\"The LAS file is empty or could not be read.\")\n}\n\nif (is.null(las@data$Z)) {\n  stop(\"The LAS file does not contain Z coordinates.\")\n}\n\nif (!\"Zref\" %in% names(las@data)) {\n  las &lt;- normalize_height(las, tin())\n}\n\ntemp_las_file &lt;- tempfile(fileext = \".las\")\nwriteLAS(las, temp_las_file)\n\ncompute_lai &lt;- function(las_file_path) {\n  lad_voxels &lt;- lad.voxels(las_file_path, grain.size = 25)\n  lai_raster &lt;- lai.raster(lad_voxels)\n  return(lai_raster)\n}\n\ntiming_results &lt;- data.frame(software = character(),\n                             time = numeric(),\n                             stringsAsFactors = FALSE)\n\nfor (i in 1:100) {\n  start_time &lt;- Sys.time()\n  lai_result &lt;- compute_lai(temp_las_file)\n  end_time &lt;- Sys.time()\n  iteration_time &lt;- as.numeric(difftime(end_time, start_time, units = \"secs\"))\n\n  timing_results &lt;- rbind(timing_results, data.frame(software = \"R::leafR\", time = iteration_time))\n  cat(sprintf(\"Iteration %d completed in %.2f seconds.\\n\", i, iteration_time))\n}\n\nwrite.csv(timing_results, file = \"timing_results.csv\", row.names = FALSE)\n\ncat(sprintf(\"Total time for 100 iterations: %.2f seconds.\\n\", sum(timing_results$time)))\n\nunlink(temp_las_file)\n</code></pre>"},{"location":"benchmarks/#reference","title":"Reference","text":"<p>Almeida, Danilo Roberti Alves de, Scott Christopher Stark, Carlos Alberto Silva, Caio Hamamura, and Ruben Valbuena. 2021. \"leafR: Calculates the Leaf Area Index (LAD) and Other Related Functions.\"Manual. https://CRAN.R-project.org/package=leafR.</p>"},{"location":"code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"code_of_conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting ipercival[at]gmail.com. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p> <p>For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq</p>"},{"location":"contributing/","title":"Contributing to PyForestScan","text":"<p>Thank you for contributing to PyForestScan! Your involvement helps make this project a great tool for point cloud data processing and visualization of forest structure.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, please follow our Code of Conduct.</p>"},{"location":"contributing/#how-can-i-contribute","title":"How Can I Contribute?","text":""},{"location":"contributing/#reporting-bugs","title":"Reporting Bugs","text":"<ul> <li> <p>Check Existing Issues \u2014 Before opening a new bug report, see if the issue has already been reported. If it has, add any additional details in a comment.</p> </li> <li> <p>Submit a Report \u2014 If the issue hasn't been reported, open a new issue and fill out the provided template.</p> </li> </ul>"},{"location":"contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>Have an idea to improve PyForestScan? Please open an issue to discuss your suggestion.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>To contribute via pull requests:</p> <ol> <li>Fork the Repository \u2014 Fork the PyForestScan repository and clone it locally.</li> <li>Create a Branch \u2014 Make changes in a new branch. Use descriptive names like <code>feat/</code>, <code>fix/</code>, or <code>docs/</code> followed by the feature or fix name.</li> <li>Commit Your Changes \u2014 Write a clear commit message describing your changes.</li> <li>Push to Your Fork \u2014 Push the branch to your fork on GitHub.</li> <li>Create a Pull Request \u2014 Open a pull request (PR) in the PyForestScan repository. Link any relevant issues.</li> <li>Code Review \u2014 A maintainer will review your changes. You may need to make updates based on feedback.</li> <li>Merge \u2014 Once approved, your PR will be merged into the main codebase.</li> </ol>"},{"location":"contributing/#style-guidelines","title":"Style Guidelines","text":""},{"location":"contributing/#python","title":"Python","text":"<ul> <li>Follow the PEP 8 style guide.</li> <li>Use type hints in functions.</li> <li>Add documentation to public APIs.</li> </ul>"},{"location":"contributing/#git-commit-messages","title":"Git Commit Messages","text":"<ul> <li>Use present tense (\"Add feature\" not \"Added feature\").</li> <li>Limit the first line to 72 characters or fewer.</li> <li>Reference related issues and PRs when relevant.</li> </ul>"},{"location":"contributing/#releasing-a-new-version","title":"Releasing a New Version","text":""},{"location":"contributing/#steps-for-creating-a-new-release","title":"Steps for Creating a New Release","text":"<ol> <li> <p>Ensure <code>main</code> is up to date:    Confirm all changes intended for the release are merged into the <code>main</code> branch.</p> </li> <li> <p>Update the version:    Manually bump the version number in <code>setup.py</code> based on the type of release (major, minor, or patch) following semantic versioning.</p> </li> <li> <p>Create a new tag:    Tag the release with the new version using the format <code>vX.X.X</code>. For example:    <pre><code>git tag v1.2.0\ngit push origin v1.2.0\n</code></pre></p> </li> <li> <p>Deploy to PyPI:    The GitHub Actions workflow will automatically build and deploy the package to PyPI once the tag is pushed.</p> </li> </ol>"},{"location":"contributing/#semantic-versioning-guidelines","title":"Semantic Versioning Guidelines","text":"<ul> <li>Major version: For incompatible API changes.</li> <li>Minor version: For backward-compatible features.</li> <li>Patch version: For backward-compatible bug fixes.</li> </ul>"},{"location":"contributing/#additional-notes","title":"Additional Notes","text":"<ul> <li>Ensure compatibility with the latest dependencies.</li> <li>Update documentation when adding or changing features.</li> </ul>"},{"location":"examples/","title":"Examples","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>To use PyForestScan, you need to have both PDAL (Point Data Abstraction Library) and GDAL (Geospatial Data Abstraction Library) installed. PDAL is a powerful library for working with point cloud data, and PyForestScan relies on it for many core functions.  GDAL contains the necessary raster processing capabilities and is used for writing geospatial raster data.</p>"},{"location":"installation/#gdal-and-pdal","title":"GDAL and PDAL","text":"<p>For complete installation guides, please visit the GDAL official documentation and PDAL official documentation sites. However, for a quick start, it is recommended to use conda to install both PDAL and GDAL, as it handles dependencies and installation paths efficiently. Once these dependencies are installed, you can then use pip to install pyforestscan within the same environment.</p> <p>Steps to install PDAL and GDAL:</p> <ol> <li>Install PDAL and GDAL using <code>conda</code>:</li> </ol> <pre><code>conda create -n pyforestscan_env -c conda-forge pdal gdal\n</code></pre> <ol> <li>Activate the conda env:</li> </ol> <pre><code>conda activate pyforestscan_env\n</code></pre> <p>For more information on PDAL and its capabilities, visit the official PDAL documentation: https://pdal.io/en/latest/.</p>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>Once dependencies are installed, PyForestScan can be installed from PyPI:</p> <pre><code>pip install pyforestscan\n</code></pre>"},{"location":"installation/#install-from-github","title":"Install from GitHub","text":"<p>It is also possible to install the latest development version from GitHub using Git:</p> <p>pip install git+https://github.com/iosefa/pyforestscan</p> <p>At any time, you can verify your installation:</p> <pre><code>pip show pyforestscan\n</code></pre>"},{"location":"installation/#docker","title":"Docker","text":"<p>A docker environment with <code>pyforestscan</code> is also available and includes jupyter with example notebooks and data. To use the docker environment:</p> <pre><code>docker run -it --rm -p 8888:8888 iosefa/pyforestscan:latest\n</code></pre> <p>This will launch a jupyter notebook. </p>"},{"location":"api/calculate/","title":"Calculate Module","text":""},{"location":"api/calculate/#pyforestscan.calculate.assign_voxels","title":"<code>assign_voxels(arr, voxel_resolution)</code>","text":"<p>Assigns voxel grids to spatial data points based on the specified resolutions.</p> <p>:param arr:     Input array-like object containing point cloud data with 'X', 'Y', and 'HeightAboveGround' fields. :type arr: numpy.ndarray :param voxel_resolution:     The resolution for x, y, and z dimensions of the voxel grid. :type voxel_resolution: tuple of floats</p> <p>:return:     A tuple containing the histogram of the voxel grid (with corrected orientation) and the extent of the point cloud. :rtype: tuple of (numpy.ndarray, list)</p> Source code in <code>pyforestscan/calculate.py</code> <pre><code>def assign_voxels(arr, voxel_resolution):\n    \"\"\"\n    Assigns voxel grids to spatial data points based on the specified resolutions.\n\n    :param arr:\n        Input array-like object containing point cloud data with 'X', 'Y', and 'HeightAboveGround' fields.\n    :type arr: numpy.ndarray\n    :param voxel_resolution:\n        The resolution for x, y, and z dimensions of the voxel grid.\n    :type voxel_resolution: tuple of floats\n\n    :return:\n        A tuple containing the histogram of the voxel grid (with corrected orientation) and the extent of the point cloud.\n    :rtype: tuple of (numpy.ndarray, list)\n    \"\"\"\n    x_resolution, y_resolution, z_resolution = voxel_resolution\n\n    try:\n        x = arr['X']\n        y = arr['Y']\n        z = arr['HeightAboveGround']\n    except ValueError:\n        raise ValueError(\"Point cloud data missing 'X', 'Y', or 'HeightAboveGround' fields.\")\n\n    if x.size == 0 or y.size == 0 or z.size == 0:\n        raise ValueError(\"Point cloud data contains no points.\")\n\n    x_min, x_max = x.min(), x.max()\n    y_min, y_max = y.min(), y.max()\n    z_min, z_max = z.min(), z.max()\n\n    x_bins = np.arange(x_min, x_max + x_resolution, x_resolution)\n    y_bins = np.arange(y_min, y_max + y_resolution, y_resolution)\n    z_bins = np.arange(z_min, z_max + z_resolution, z_resolution)\n\n    histogram, edges = np.histogramdd(\n        np.stack((x, y, z), axis=-1),\n        bins=(x_bins, y_bins, z_bins)\n    )\n    histogram = histogram[:, ::-1, :]\n\n    extent = [x_min, x_max, y_min, y_max]\n\n    return histogram, extent\n</code></pre>"},{"location":"api/calculate/#pyforestscan.calculate.calculate_chm","title":"<code>calculate_chm(arr, voxel_resolution, interpolation='linear')</code>","text":"<p>Calculate Canopy Height Model (CHM) for a given voxel size. The height is the highest HeightAboveGround value in each (x, y) voxel.</p> <p>:param arr: Input array-like object containing point cloud data with 'X', 'Y', and 'HeightAboveGround' fields. :type arr: numpy.ndarray :param voxel_resolution:     The resolution for x and y dimensions of the voxel grid. :param interpolation:     Method for interpolating pixel gaps in the CHM. Supported methods are: \"nearest\", \"linear\", \"cubic\", or None.     If None, no interpolation is performed. :type voxel_resolution: tuple of floats (x_resolution, y_resolution)</p> <p>:return:     A tuple containing the CHM as a 2D numpy array and the spatial extent. :rtype: tuple of (numpy.ndarray, list)</p> Source code in <code>pyforestscan/calculate.py</code> <pre><code>def calculate_chm(arr, voxel_resolution, interpolation=\"linear\"):\n    \"\"\"\n    Calculate Canopy Height Model (CHM) for a given voxel size.\n    The height is the highest HeightAboveGround value in each (x, y) voxel.\n\n    :param arr: Input array-like object containing point cloud data with 'X', 'Y', and 'HeightAboveGround' fields.\n    :type arr: numpy.ndarray\n    :param voxel_resolution:\n        The resolution for x and y dimensions of the voxel grid.\n    :param interpolation:\n        Method for interpolating pixel gaps in the CHM. Supported methods are: \"nearest\", \"linear\", \"cubic\", or None.\n        If None, no interpolation is performed.\n    :type voxel_resolution: tuple of floats (x_resolution, y_resolution)\n\n    :return:\n        A tuple containing the CHM as a 2D numpy array and the spatial extent.\n    :rtype: tuple of (numpy.ndarray, list)\n    \"\"\"\n    x_resolution, y_resolution = voxel_resolution[:2]\n    x = arr['X']\n    y = arr['Y']\n    z = arr['HeightAboveGround']\n\n    x_min, x_max = x.min(), x.max()\n    y_min, y_max = y.min(), y.max()\n\n    x_bins = np.arange(x_min, x_max + x_resolution, x_resolution)\n    y_bins = np.arange(y_min, y_max + y_resolution, y_resolution)\n\n    x_indices = np.digitize(x, x_bins) - 1\n    y_indices = np.digitize(y, y_bins) - 1\n\n    chm = np.full((len(x_bins) - 1, len(y_bins) - 1), np.nan)\n\n    for xi, yi, zi in zip(x_indices, y_indices, z):\n        if 0 &lt;= xi &lt; chm.shape[0] and 0 &lt;= yi &lt; chm.shape[1]:\n            if np.isnan(chm[xi, yi]) or zi &gt; chm[xi, yi]:\n                chm[xi, yi] = zi\n\n    if interpolation is not None:\n        mask = np.isnan(chm)\n\n        x_grid, y_grid = np.meshgrid(\n            (x_bins[:-1] + x_bins[1:]) / 2,\n            (y_bins[:-1] + y_bins[1:]) / 2\n        )\n\n        valid_mask = ~mask.flatten()\n        valid_x = x_grid.flatten()[valid_mask]\n        valid_y = y_grid.flatten()[valid_mask]\n        valid_values = chm.flatten()[valid_mask]\n\n        interp_x = x_grid.flatten()[mask.flatten()]\n        interp_y = y_grid.flatten()[mask.flatten()]\n\n        chm[mask] = griddata(\n            points=(valid_x, valid_y),\n            values=valid_values,\n            xi=(interp_x, interp_y),\n            method=interpolation\n        )\n\n    chm = np.flip(chm, axis=1)\n    extent = [x_min, x_max, y_min, y_max]\n\n    return chm, extent\n</code></pre>"},{"location":"api/calculate/#pyforestscan.calculate.calculate_fhd","title":"<code>calculate_fhd(voxel_returns)</code>","text":"<p>Calculate the Foliage Height Diversity (FHD) for a given set of voxel returns.</p> <p>This function computes Foliage Height Diversity by calculating the entropy of the voxel return proportions along the z-axis, which represents vertical structure in the canopy.</p> <p>:param voxel_returns:     A numpy array of shape (x, y, z) representing voxel returns, where x and y are spatial     dimensions, and z represents height bins (or layers along the vertical axis).</p> <p>:return:     A numpy array of shape (x, y) representing the FHD values for each (x, y) location.     Areas with no voxel returns will have NaN values.</p> Source code in <code>pyforestscan/calculate.py</code> <pre><code>def calculate_fhd(voxel_returns):\n    \"\"\"\n    Calculate the Foliage Height Diversity (FHD) for a given set of voxel returns.\n\n    This function computes Foliage Height Diversity by calculating the entropy\n    of the voxel return proportions along the z-axis, which represents vertical structure\n    in the canopy.\n\n    :param voxel_returns:\n        A numpy array of shape (x, y, z) representing voxel returns, where x and y are spatial\n        dimensions, and z represents height bins (or layers along the vertical axis).\n\n    :return:\n        A numpy array of shape (x, y) representing the FHD values for each (x, y) location.\n        Areas with no voxel returns will have NaN values.\n    \"\"\"\n    sum_counts = np.sum(voxel_returns, axis=2, keepdims=True)\n\n    with np.errstate(divide='ignore', invalid='ignore'):\n        proportions = np.divide(\n            voxel_returns,\n            sum_counts,\n            out=np.zeros_like(voxel_returns, dtype=float),\n            where=sum_counts != 0\n        )\n\n    fhd = entropy(proportions, axis=2)\n\n    fhd[sum_counts.squeeze() == 0] = np.nan\n\n    return fhd\n</code></pre>"},{"location":"api/calculate/#pyforestscan.calculate.calculate_pad","title":"<code>calculate_pad(voxel_returns, voxel_height, beer_lambert_constant=None)</code>","text":"<p>Calculate the Plant Area Density (PAD) using the Beer-Lambert Law.</p> <p>:param voxel_returns: numpy array representing the returns from each voxel (x, y, z). :param voxel_height: float, height of each voxel. :param beer_lambert_constant: Optional Beer-Lambert constant, defaults to 1 if not provided.</p> <p>:return: numpy array containing PAD values for each voxel.</p> Source code in <code>pyforestscan/calculate.py</code> <pre><code>def calculate_pad(voxel_returns, voxel_height, beer_lambert_constant=None):\n    \"\"\"\n    Calculate the Plant Area Density (PAD) using the Beer-Lambert Law.\n\n    :param voxel_returns: numpy array representing the returns from each voxel (x, y, z).\n    :param voxel_height: float, height of each voxel.\n    :param beer_lambert_constant: Optional Beer-Lambert constant, defaults to 1 if not provided.\n\n    :return: numpy array containing PAD values for each voxel.\n    \"\"\"\n    shots_in = np.cumsum(voxel_returns[::-1], axis=2)[::-1]\n    shots_through = shots_in - voxel_returns\n\n    with np.errstate(divide='ignore', invalid='ignore'):\n        division_result = np.true_divide(shots_in, shots_through)\n        division_result = np.where((shots_in == 0) &amp; (shots_through == 0), 1, division_result)\n        division_result = np.where((shots_through == 0) &amp; (shots_in != 0), np.nan, division_result)\n\n        pad = np.log(division_result) * (1 / (beer_lambert_constant or 1) / voxel_height)\n\n    pad = np.where(np.isfinite(pad) &amp; (pad &gt; 0), pad, 0)\n\n    return pad\n</code></pre>"},{"location":"api/calculate/#pyforestscan.calculate.calculate_pai","title":"<code>calculate_pai(pad, min_height=1, max_height=None)</code>","text":"<p>Calculate Plant Area Index (PAI) from PAD data by summing LAD values across the Z (height) axis.</p> <p>:param pad: A 3D numpy array representing the Plant Area Density (PAD) values. :param min_height: Minimum height index for summing PAD values (optional). :param max_height: Maximum height index for summing PAD values (optional).</p> <p>:return: A 2D numpy array with PAI values for each (x, y) voxel column.</p> Source code in <code>pyforestscan/calculate.py</code> <pre><code>def calculate_pai(pad, min_height=1, max_height=None):\n    \"\"\"\n    Calculate Plant Area Index (PAI) from PAD data by summing LAD values across the Z (height) axis.\n\n    :param pad: A 3D numpy array representing the Plant Area Density (PAD) values.\n    :param min_height: Minimum height index for summing PAD values (optional).\n    :param max_height: Maximum height index for summing PAD values (optional).\n\n    :return: A 2D numpy array with PAI values for each (x, y) voxel column.\n    \"\"\"\n    if max_height is None:\n        max_height = pad.shape[2]\n    if min_height &gt;= max_height:\n        raise ValueError(\"Minimum height index must be less than maximum height index.\")\n\n    pai = np.nansum(pad[:, :, min_height:max_height], axis=2)\n\n    return pai\n</code></pre>"},{"location":"api/calculate/#pyforestscan.calculate.generate_dtm","title":"<code>generate_dtm(ground_points, resolution=2.0)</code>","text":"<p>Generates a Digital Terrain Model (DTM) raster from classified ground points.</p> <p>:param ground_points: list     Point cloud arrays of classified ground points. :type ground_points: list :param resolution: float, spatial resolution of the DTM in meters. :return: tuple     A tuple containing the DTM as a 2D NumPy array and the spatial extent [x_min, x_max, y_min, y_max]. :rtype: tuple (numpy.ndarray, list) :raises ValueError:     If no ground points are found for DTM generation. :raises KeyError:     If point cloud data is missing 'X', 'Y', or 'Z' fields.</p> Source code in <code>pyforestscan/calculate.py</code> <pre><code>def generate_dtm(ground_points, resolution=2.0):\n    \"\"\"\n    Generates a Digital Terrain Model (DTM) raster from classified ground points.\n\n    :param ground_points: list\n        Point cloud arrays of classified ground points.\n    :type ground_points: list\n    :param resolution: float, spatial resolution of the DTM in meters.\n    :return: tuple\n        A tuple containing the DTM as a 2D NumPy array and the spatial extent [x_min, x_max, y_min, y_max].\n    :rtype: tuple (numpy.ndarray, list)\n    :raises ValueError:\n        If no ground points are found for DTM generation.\n    :raises KeyError:\n        If point cloud data is missing 'X', 'Y', or 'Z' fields.\n    \"\"\"\n    #todo: add parameter to allow interpolation of NA values.\n    try:\n        x = np.array([pt['X'] for array in ground_points for pt in array])\n        y = np.array([pt['Y'] for array in ground_points for pt in array])\n        z = np.array([pt['Z'] for array in ground_points for pt in array])\n    except ValueError:\n        raise ValueError(\"Ground point cloud data missing 'X', 'Y', or 'Z' fields.\")\n\n    x_min, x_max = x.min(), x.max()\n    y_min, y_max = y.min(), y.max()\n\n    x_bins = np.arange(x_min, x_max + resolution, resolution)\n    y_bins = np.arange(y_min, y_max + resolution, resolution)\n\n    x_indices = np.digitize(x, x_bins) - 1\n    y_indices = np.digitize(y, y_bins) - 1\n\n    dtm = np.full((len(x_bins) - 1, len(y_bins) - 1), np.nan)\n\n    for xi, yi, zi in zip(x_indices, y_indices, z):\n        if 0 &lt;= xi &lt; dtm.shape[0] and 0 &lt;= yi &lt; dtm.shape[1]:\n            if np.isnan(dtm[xi, yi]) or zi &lt; dtm[xi, yi]:\n                dtm[xi, yi] = zi\n\n    dtm = np.fliplr(dtm)\n\n    extent = [x_min, x_max, y_min, y_max]\n\n    return dtm, extent\n</code></pre>"},{"location":"api/filters/","title":"Filters Module","text":""},{"location":"api/filters/#pyforestscan.filters.classify_ground_points","title":"<code>classify_ground_points(arrays, ignore_class='Classification[7:7]', cell=1.0, cut=0.0, returns='last,only', scalar=1.25, slope=0.15, threshold=0.5, window=18.0)</code>","text":"<p>Applies the SMRF filter to classify ground points in the point cloud.</p> <p>:param arrays: list     Cleaned point cloud arrays after outlier removal. :type arrays: list :param ignore_class: str, classification codes to ignore during filtering. :param cell: float, cell size in meters. :param cut: float, cut net size (0 skips net cutting). :param returns: str, return types to include in output (\"first\", \"last\", \"intermediate\", \"only\"). :param scalar: float, elevation scalar. :param slope: float, slope threshold for ground classification. :param threshold: float, elevation threshold. :param window: float, max window size in meters. :return: list     Point cloud arrays with classified ground points. :rtype: list :raises RuntimeError:     If there's an error during the pipeline execution. :raises ValueError:     If no data is returned after SMRF classification.</p> Source code in <code>pyforestscan/filters.py</code> <pre><code>def classify_ground_points(\n        arrays,\n        ignore_class=\"Classification[7:7]\",\n        cell=1.0,\n        cut=0.0,\n        returns=\"last,only\",\n        scalar=1.25,\n        slope=0.15,\n        threshold=0.5,\n        window=18.0\n):\n    \"\"\"\n    Applies the SMRF filter to classify ground points in the point cloud.\n\n    :param arrays: list\n        Cleaned point cloud arrays after outlier removal.\n    :type arrays: list\n    :param ignore_class: str, classification codes to ignore during filtering.\n    :param cell: float, cell size in meters.\n    :param cut: float, cut net size (0 skips net cutting).\n    :param returns: str, return types to include in output (\"first\", \"last\", \"intermediate\", \"only\").\n    :param scalar: float, elevation scalar.\n    :param slope: float, slope threshold for ground classification.\n    :param threshold: float, elevation threshold.\n    :param window: float, max window size in meters.\n    :return: list\n        Point cloud arrays with classified ground points.\n    :rtype: list\n    :raises RuntimeError:\n        If there's an error during the pipeline execution.\n    :raises ValueError:\n        If no data is returned after SMRF classification.\n    \"\"\"\n    pipeline_stages = [\n        _filter_smrf(\n            cell=cell,\n            cut=cut,\n            ignore=ignore_class,\n            returns=returns,\n            scalar=scalar,\n            slope=slope,\n            threshold=threshold,\n            window=window\n        )\n    ]\n\n    try:\n        pipeline = _build_pdal_pipeline(arrays, pipeline_stages)\n    except RuntimeError as e:\n        raise RuntimeError(f\"SMRF Classification Pipeline Failed: {e}\")\n\n    processed_arrays = pipeline.arrays\n\n    if not processed_arrays:\n        raise ValueError(\"No data returned after SMRF classification.\")\n\n    return processed_arrays\n</code></pre>"},{"location":"api/filters/#pyforestscan.filters.filter_ground","title":"<code>filter_ground(arrays)</code>","text":"<p>Applies a filter to remove ground points (classification 2) from the input arrays.</p> <p>:param arrays: List of point cloud arrays to be processed. :type arrays: list :return: Processed point cloud arrays after removing ground points. :rtype: list</p> Source code in <code>pyforestscan/filters.py</code> <pre><code>def filter_ground(arrays):\n    \"\"\"\n    Applies a filter to remove ground points (classification 2) from the input arrays.\n\n    :param arrays: List of point cloud arrays to be processed.\n    :type arrays: list\n    :return: Processed point cloud arrays after removing ground points.\n    :rtype: list\n    \"\"\"\n    pipeline = _build_pdal_pipeline(arrays, [_filter_ground()])\n    return pipeline.arrays\n</code></pre>"},{"location":"api/filters/#pyforestscan.filters.filter_hag","title":"<code>filter_hag(arrays, lower_limit=0, upper_limit=None)</code>","text":"<p>Applies a Height Above Ground (HAG) filter to the input arrays.</p> <p>:param arrays: List of point cloud arrays to be processed. :type arrays: list :param lower_limit: The minimum value for the height filter, defaults to 0. :type lower_limit: int, optional :param upper_limit: The maximum value for the height filter, defaults to None. :type upper_limit: int, optional :return: Processed point cloud arrays after applying the HAG filter. :rtype: list :raises ValueError: If upper_limit is less than lower_limit.</p> Source code in <code>pyforestscan/filters.py</code> <pre><code>def filter_hag(arrays, lower_limit=0, upper_limit=None):\n    \"\"\"\n    Applies a Height Above Ground (HAG) filter to the input arrays.\n\n    :param arrays: List of point cloud arrays to be processed.\n    :type arrays: list\n    :param lower_limit: The minimum value for the height filter, defaults to 0.\n    :type lower_limit: int, optional\n    :param upper_limit: The maximum value for the height filter, defaults to None.\n    :type upper_limit: int, optional\n    :return: Processed point cloud arrays after applying the HAG filter.\n    :rtype: list\n    :raises ValueError: If upper_limit is less than lower_limit.\n    \"\"\"\n    pipeline = _build_pdal_pipeline(arrays, [_filter_hag(lower_limit, upper_limit)])\n    return pipeline.arrays\n</code></pre>"},{"location":"api/filters/#pyforestscan.filters.filter_select_ground","title":"<code>filter_select_ground(arrays)</code>","text":"<p>Applies a filter to select ground points (classification 2) from the input arrays.</p> <p>:param arrays: List of point cloud arrays to be processed. :type arrays: list :return: Processed point cloud arrays after removing ground points. :rtype: list</p> Source code in <code>pyforestscan/filters.py</code> <pre><code>def filter_select_ground(arrays):\n    \"\"\"\n    Applies a filter to select ground points (classification 2) from the input arrays.\n\n    :param arrays: List of point cloud arrays to be processed.\n    :type arrays: list\n    :return: Processed point cloud arrays after removing ground points.\n    :rtype: list\n    \"\"\"\n    pipeline = _build_pdal_pipeline(arrays, [_select_ground()])\n    return pipeline.arrays\n</code></pre>"},{"location":"api/filters/#pyforestscan.filters.remove_outliers_and_clean","title":"<code>remove_outliers_and_clean(arrays, mean_k=8, multiplier=3.0)</code>","text":"<p>Removes statistical outliers from the point cloud to enhance data quality.</p> <p>:param arrays: list     List of point cloud arrays obtained from read_lidar. :type point_cloud_arrays: list :param mean_k: int, number of nearest neighbors for outlier removal. :param multiplier: float, standard deviation multiplier for outlier removal. :return: list     Cleaned array of point cloud data without outliers. :rtype: list :raises RuntimeError:     If there's an error during the pipeline execution. :raises ValueError:     If no data is returned after outlier removal.</p> Source code in <code>pyforestscan/filters.py</code> <pre><code>def remove_outliers_and_clean(arrays, mean_k=8, multiplier=3.0):\n    \"\"\"\n    Removes statistical outliers from the point cloud to enhance data quality.\n\n    :param arrays: list\n        List of point cloud arrays obtained from read_lidar.\n    :type point_cloud_arrays: list\n    :param mean_k: int, number of nearest neighbors for outlier removal.\n    :param multiplier: float, standard deviation multiplier for outlier removal.\n    :return: list\n        Cleaned array of point cloud data without outliers.\n    :rtype: list\n    :raises RuntimeError:\n        If there's an error during the pipeline execution.\n    :raises ValueError:\n        If no data is returned after outlier removal.\n    \"\"\"\n    pipeline_stages = [\n        _filter_statistical_outlier(mean_k=mean_k, multiplier=multiplier)\n    ]\n\n    try:\n        pipeline = _build_pdal_pipeline(arrays, pipeline_stages)\n    except RuntimeError as e:\n        raise RuntimeError(f\"Outlier Removal Pipeline Failed: {e}\")\n\n    processed_arrays = pipeline.arrays\n\n    if not processed_arrays:\n        raise ValueError(\"No data returned after outlier removal.\")\n\n    return processed_arrays\n</code></pre>"},{"location":"api/handlers/","title":"Handlers Module","text":""},{"location":"api/handlers/#pyforestscan.handlers.create_geotiff","title":"<code>create_geotiff(layer, output_file, crs, spatial_extent, nodata=-9999)</code>","text":"<p>Creates a GeoTIFF file from the given data layer. Note, it performs a transpose on the layer.</p> <p>:param layer: The data layer to be written into the GeoTIFF file. Assumes (X, Y) shape. :type layer: numpy.ndarray :param output_file: The path where the GeoTIFF file will be saved. :type output_file: str :param crs: The coordinate reference system for the GeoTIFF. :type crs: str :param spatial_extent: The spatial extent of the data, defined as (x_min, x_max, y_min, y_max). :type spatial_extent: tuple :param nodata: The value to use for NoData areas in the GeoTIFF. Defaults to -9999. :type nodata: float or int, optional :return: None :raises rasterio.errors.RasterioError: If there is an error in creating the GeoTIFF. :raises ValueError: If the layer has invalid dimensions or the spatial extent is invalid.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def create_geotiff(layer, output_file, crs, spatial_extent, nodata=-9999):\n    \"\"\"\n    Creates a GeoTIFF file from the given data layer. Note, it performs a transpose on the layer.\n\n    :param layer: The data layer to be written into the GeoTIFF file. Assumes (X, Y) shape.\n    :type layer: numpy.ndarray\n    :param output_file: The path where the GeoTIFF file will be saved.\n    :type output_file: str\n    :param crs: The coordinate reference system for the GeoTIFF.\n    :type crs: str\n    :param spatial_extent: The spatial extent of the data, defined as (x_min, x_max, y_min, y_max).\n    :type spatial_extent: tuple\n    :param nodata: The value to use for NoData areas in the GeoTIFF. Defaults to -9999.\n    :type nodata: float or int, optional\n    :return: None\n    :raises rasterio.errors.RasterioError: If there is an error in creating the GeoTIFF.\n    :raises ValueError: If the layer has invalid dimensions or the spatial extent is invalid.\n    \"\"\"\n    layer = np.nan_to_num(layer, nan=-9999)\n\n    x_min, x_max, y_min, y_max = spatial_extent\n\n    if layer.size == 0 or layer.shape[0] == 0 or layer.shape[1] == 0:\n        raise ValueError(f\"Invalid layer dimensions: {layer.shape}. Cannot create GeoTIFF.\")\n\n    if x_max &lt;= x_min or y_max &lt;= y_min:\n        raise ValueError(f\"Invalid spatial extent: {spatial_extent}.\")\n\n    layer = layer.T\n\n    transform = from_bounds(\n        x_min, y_min, x_max, y_max,\n        layer.shape[1], layer.shape[0]\n    )\n\n    with rasterio.open(\n            output_file, 'w',\n            driver='GTiff',\n            height=layer.shape[0],\n            width=layer.shape[1],\n            count=1,\n            dtype=layer.dtype.name,\n            crs=crs,\n            transform=transform,\n            nodata=nodata\n    ) as new_dataset:\n        new_dataset.write(layer, 1)\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.get_raster_epsg","title":"<code>get_raster_epsg(dtm_path)</code>","text":"<p>Retrieve the EPSG code from a raster file.</p> <p>:param dtm_path: str     The file path to the raster file. :return: str     The EPSG code as a string. :raises FileNotFoundError:     If the specified file does not exist.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def get_raster_epsg(dtm_path):\n    \"\"\"\n    Retrieve the EPSG code from a raster file.\n\n    :param dtm_path: str\n        The file path to the raster file.\n    :return: str\n        The EPSG code as a string.\n    :raises FileNotFoundError:\n        If the specified file does not exist.\n    \"\"\"\n    if not os.path.isfile(dtm_path):\n        raise FileNotFoundError(f\"No such file: '{dtm_path}'\")\n    with rasterio.open(dtm_path) as dtm:\n        return dtm.crs.to_string()\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.load_polygon_from_file","title":"<code>load_polygon_from_file(vector_file_path, index=0)</code>","text":"<p>Load a polygon geometry and its CRS from a given vector file.</p> <p>:param vector_file_path: str, Path to the vector file containing the polygon. :param index: int, optional, Index of the polygon to be loaded (default is 0). :return: tuple, containing the Well-Known Text (WKT) representation of the polygon and the coordinate reference system (CRS) as a string. :raises FileNotFoundError: If the vector file does not exist. :raises ValueError: If the file cannot be read or is not a valid vector file format.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def load_polygon_from_file(vector_file_path, index=0):\n    \"\"\"\n    Load a polygon geometry and its CRS from a given vector file.\n\n    :param vector_file_path: str, Path to the vector file containing the polygon.\n    :param index: int, optional, Index of the polygon to be loaded (default is 0).\n    :return: tuple, containing the Well-Known Text (WKT) representation of the polygon and the coordinate reference system (CRS) as a string.\n    :raises FileNotFoundError: If the vector file does not exist.\n    :raises ValueError: If the file cannot be read or is not a valid vector file format.\n    \"\"\"\n    if not os.path.isfile(vector_file_path):\n        raise FileNotFoundError(f\"No such file: '{vector_file_path}'\")\n\n    try:\n        gdf = gpd.read_file(vector_file_path)\n    except Exception as e:\n        raise ValueError(f\"Unable to read file: {vector_file_path}. Ensure it is a valid vector file format.\") from e\n\n    polygon = gdf.loc[index, 'geometry']\n    if isinstance(polygon, MultiPolygon):\n        polygon = list(polygon.geoms)[0]\n    return polygon.wkt, gdf.crs.to_string()\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.read_lidar","title":"<code>read_lidar(input_file, srs, bounds=None, thin_radius=None, hag=False, hag_dtm=False, dtm=None, crop_poly=False, poly=None)</code>","text":"<p>Reads and processes a LiDAR point cloud file using PDAL based on specified options.</p> <p>:param input_file: str, The path to the input LiDAR file. Supported formats are .las, .laz, .copc, and .copc.laz. :param srs: str, The Spatial Reference System (SRS) of the point cloud. :param bounds:  Bounds within which to crop the data. Only in effect for ept format. Must be of the form: ([xmin, xmax], [ymin, ymax], [zmin, zmax]) :param thin_radius: float, optional, The radius for thinning the point cloud. Must be a positive number. :param hag: bool, optional, If True, calculate Height Above Ground (HAG) using Delaunay triangulation. :param hag_dtm: bool, optional, If True, calculate Height Above Ground (HAG) using a DTM file. :param dtm: str, optional, The path to the DTM file used when hag_dtm is True. Must be a .tif file. :param crop_poly: bool, optional, If True, crop the point cloud using the polygon defined in the poly file. :param poly: str, optional, The path to the polygon file used for cropping OR the WKT of the Polygon geometry.</p> <p>:return: numpy.ndarray, The processed point cloud data or None if no data is retrieved.</p> <p>:raises FileNotFoundError: If the input file, polygon file, or DTM file does not exist. :raises ValueError: If the input file extension is unsupported, thinning radius is non-positive, or                     both 'hag' and 'hag_dtm' are True simultaneously, or the DTM file path is not                     provided when 'hag_dtm' is True.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def read_lidar(input_file, srs, bounds=None, thin_radius=None, hag=False, hag_dtm=False, dtm=None, crop_poly=False, poly=None):\n    \"\"\"\n    Reads and processes a LiDAR point cloud file using PDAL based on specified options.\n\n    :param input_file: str, The path to the input LiDAR file. Supported formats are .las, .laz, .copc, and .copc.laz.\n    :param srs: str, The Spatial Reference System (SRS) of the point cloud.\n    :param bounds:  Bounds within which to crop the data. Only in effect for ept format. Must be of the form: ([xmin, xmax], [ymin, ymax], [zmin, zmax])\n    :param thin_radius: float, optional, The radius for thinning the point cloud. Must be a positive number.\n    :param hag: bool, optional, If True, calculate Height Above Ground (HAG) using Delaunay triangulation.\n    :param hag_dtm: bool, optional, If True, calculate Height Above Ground (HAG) using a DTM file.\n    :param dtm: str, optional, The path to the DTM file used when hag_dtm is True. Must be a .tif file.\n    :param crop_poly: bool, optional, If True, crop the point cloud using the polygon defined in the poly file.\n    :param poly: str, optional, The path to the polygon file used for cropping OR the WKT of the Polygon geometry.\n\n    :return: numpy.ndarray, The processed point cloud data or None if no data is retrieved.\n\n    :raises FileNotFoundError: If the input file, polygon file, or DTM file does not exist.\n    :raises ValueError: If the input file extension is unsupported, thinning radius is non-positive, or\n                        both 'hag' and 'hag_dtm' are True simultaneously, or the DTM file path is not\n                        provided when 'hag_dtm' is True.\n    \"\"\"\n    if not _is_url(input_file) and not os.path.isfile(input_file):\n        raise FileNotFoundError(f\"No such file: '{input_file}'\")\n\n    las_extensions = ('.las', '.laz')\n    copc_extensions = ('.copc', '.copc.laz')\n    ept_file = ('ept.json')\n\n    file_lower = input_file.lower()\n    if file_lower.endswith(las_extensions):\n        reader = 'readers.las'\n    elif file_lower.endswith(copc_extensions):\n        reader = 'readers.copc'\n    elif file_lower.endswith(ept_file):\n        reader = 'readers.ept'\n    else:\n        raise ValueError(\n            \"The input file must be a .las, .laz, .copc, .copc.laz file, or an ept.json file.\"\n        )\n\n    if hag and hag_dtm:\n        raise ValueError(\"Cannot use both 'hag' and 'hag_dtm' options at the same time.\")\n\n    pipeline_stages = []\n    crs_list = []\n\n    if crop_poly:\n        if not poly:\n            raise ValueError(f\"Must provide a polygon or polygon wkt if cropping to a polygon.\")\n        if poly.strip().startswith(('POLYGON', 'MULTIPOLYGON')):\n            polygon_wkt = poly\n        else:\n            if not poly or not os.path.isfile(poly):\n                raise FileNotFoundError(f\"No such polygon file: '{poly}'\")\n            polygon_wkt, crs_vector = load_polygon_from_file(poly)\n        pipeline_stages.append(_crop_polygon(polygon_wkt))\n\n    if thin_radius is not None:\n        if thin_radius &lt;= 0:\n            raise ValueError(\"Thinning radius must be a positive number.\")\n        pipeline_stages.append(_filter_radius(thin_radius))\n\n    if hag:\n        pipeline_stages.append(_hag_delaunay())\n\n    if hag_dtm:\n        if not dtm:\n            raise ValueError(\"DTM file path must be provided when 'hag_dtm' is True.\")\n        if not os.path.isfile(dtm):\n            raise FileNotFoundError(f\"No such DTM file: '{dtm}'\")\n        if not dtm.lower().endswith('.tif'):\n            raise ValueError(\"The DTM file must be a .tif file.\")\n        crs_raster = get_raster_epsg(dtm)\n        crs_list.append(crs_raster)\n        pipeline_stages.append(_hag_raster(dtm))\n\n    base_pipeline = {\n        \"type\": reader,\n        \"spatialreference\": srs,\n        \"filename\": input_file\n    }\n    if bounds and reader == 'readers.ept':\n        base_pipeline[\"bounds\"] = f\"{bounds}\"\n    main_pipeline_json = {\n        \"pipeline\": [\n            base_pipeline\n        ] + pipeline_stages\n    }\n\n    main_pipeline = pdal.Pipeline(json.dumps(main_pipeline_json))\n    main_pipeline.execute()\n\n    point_cloud = main_pipeline.arrays\n    return point_cloud if point_cloud else None\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.simplify_crs","title":"<code>simplify_crs(crs_list)</code>","text":"<p>Converts a list of CRS representations to their corresponding EPSG codes.</p> <p>:param crs_list: List of CRS definitions to be simplified. :type crs_list: list :return: List of EPSG codes corresponding to the input CRS definitions. :rtype: list :raises CRSError: If any of the CRS definitions cannot be converted to an EPSG code.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def simplify_crs(crs_list):\n    \"\"\"\n    Converts a list of CRS representations to their corresponding EPSG codes.\n\n    :param crs_list: List of CRS definitions to be simplified.\n    :type crs_list: list\n    :return: List of EPSG codes corresponding to the input CRS definitions.\n    :rtype: list\n    :raises CRSError: If any of the CRS definitions cannot be converted to an EPSG code.\n    \"\"\"\n    epsg_codes = []\n    for crs in crs_list:\n        try:\n            crs_obj = CRS(crs)\n            epsg = crs_obj.to_epsg()\n            if epsg is None:\n                raise CRSError(f\"Cannot convert CRS '{crs}' to an EPSG code.\")\n            epsg_codes.append(epsg)\n        except CRSError as e:\n            raise CRSError(f\"Error converting CRS '{crs}': {e}\") from None\n    return epsg_codes\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.validate_crs","title":"<code>validate_crs(crs_list)</code>","text":"<p>Validate that all CRS representations in the list are identical.</p> <p>:param crs_list: List of coordinate reference systems to validate. :type crs_list: list :return: True if all CRSs match. :rtype: bool :raises ValueError: If the CRSs do not match.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def validate_crs(crs_list):\n    \"\"\"\n    Validate that all CRS representations in the list are identical.\n\n    :param crs_list: List of coordinate reference systems to validate.\n    :type crs_list: list\n    :return: True if all CRSs match.\n    :rtype: bool\n    :raises ValueError: If the CRSs do not match.\n    \"\"\"\n    simplified_crs_list = simplify_crs(crs_list)\n    if not all(crs == simplified_crs_list[0] for crs in simplified_crs_list[1:]):\n        raise ValueError(\"The CRS of the inputs do not match.\")\n    return True\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.validate_extensions","title":"<code>validate_extensions(las_file_path, dtm_file_path)</code>","text":"<p>Validates the extensions of the provided file paths to check if they match the required .las/.laz for point cloud files and .tif for DTM files.</p> <p>:param las_file_path: The file path of the point cloud file.                         Supported extensions are .las and .laz. :type las_file_path: str :param dtm_file_path: The file path of the DTM (Digital Terrain Model) file.                         Supported extension is .tif. :type dtm_file_path: str :raises ValueError: If the point cloud file does not have a .las or .laz extension. :raises ValueError: If the DTM file does not have a .tif extension.</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def validate_extensions(las_file_path, dtm_file_path):\n    \"\"\"\n    Validates the extensions of the provided file paths to check if they match\n    the required .las/.laz for point cloud files and .tif for DTM files.\n\n    :param las_file_path: The file path of the point cloud file.\n                            Supported extensions are .las and .laz.\n    :type las_file_path: str\n    :param dtm_file_path: The file path of the DTM (Digital Terrain Model) file.\n                            Supported extension is .tif.\n    :type dtm_file_path: str\n    :raises ValueError: If the point cloud file does not have a .las or .laz extension.\n    :raises ValueError: If the DTM file does not have a .tif extension.\n    \"\"\"\n    if not las_file_path.lower().endswith(('.las', '.laz')):\n        raise ValueError(\"The point cloud file must be a .las or .laz file.\")\n    if not dtm_file_path.lower().endswith('.tif'):\n        raise ValueError(\"The DTM file must be a .tif file.\")\n</code></pre>"},{"location":"api/handlers/#pyforestscan.handlers.write_las","title":"<code>write_las(arrays, output_file, srs=None, compress=True)</code>","text":"<p>Writes point cloud data to a LAS or LAZ file.</p> <p>:param arrays: The point cloud data arrays. :param output_file: The path of the output file. :param srs: Optional; Spatial Reference System to reproject the data. :param compress: Optional; Boolean flag to compress the output. Defaults to True. :raises ValueError: If 'compress' is True and output file extension is not .laz. :raises ValueError: If 'compress' is False and output file extension is not .las.</p> <p>:return: None</p> Source code in <code>pyforestscan/handlers.py</code> <pre><code>def write_las(arrays, output_file, srs=None, compress=True):\n    \"\"\"\n    Writes point cloud data to a LAS or LAZ file.\n\n    :param arrays: The point cloud data arrays.\n    :param output_file: The path of the output file.\n    :param srs: Optional; Spatial Reference System to reproject the data.\n    :param compress: Optional; Boolean flag to compress the output. Defaults to True.\n    :raises ValueError: If 'compress' is True and output file extension is not .laz.\n    :raises ValueError: If 'compress' is False and output file extension is not .las.\n\n    :return: None\n    \"\"\"\n    output_extension = os.path.splitext(output_file)[1].lower()\n\n    if compress:\n        if output_extension != '.laz':\n            raise ValueError(\"If 'compress' is True, output file must have a .laz extension.\")\n        output_format = \"writers.las\"\n    else:\n        if output_extension != '.las':\n            raise ValueError(\"If 'compress' is False, output file must have a .las extension.\")\n        output_format = \"writers.las\"\n\n    pipeline_steps = []\n\n    if srs:\n        pipeline_steps.append({\n            \"type\": \"filters.reprojection\",\n            \"in_srs\": srs,\n            \"out_srs\": srs\n        })\n\n    pipeline_steps.append({\n        \"type\": output_format,\n        \"filename\": output_file,\n        \"minor_version\": \"4\",\n        \"extra_dims\": \"all\"\n    })\n\n    pipeline_def = {\n        \"pipeline\": pipeline_steps\n    }\n\n    pipeline_json = json.dumps(pipeline_def)\n\n    if not isinstance(arrays, list):\n        arrays = [arrays]\n\n    pipeline = pdal.Pipeline(pipeline_json, arrays=arrays)\n    pipeline.execute()\n</code></pre>"},{"location":"api/pipeline/","title":"Pipeline Module","text":""},{"location":"api/process/","title":"Process Module","text":""},{"location":"api/process/#pyforestscan.process.get_bounds","title":"<code>get_bounds(ept_file)</code>","text":"<p>Extracts the spatial bounds of a point cloud from an ept file using PDAL.</p> <p>:param ept_file: Path to the ept file containing the point cloud data. :return: A tuple with bounds in the format (min_x, max_x, min_y, max_y).</p> Source code in <code>pyforestscan/process.py</code> <pre><code>def get_bounds(ept_file):\n    \"\"\"\n    Extracts the spatial bounds of a point cloud from an ept file using PDAL.\n\n    :param ept_file: Path to the ept file containing the point cloud data.\n    :return: A tuple with bounds in the format (min_x, max_x, min_y, max_y).\n    \"\"\"\n    pipeline_json = f\"\"\"\n    {{\n        \"pipeline\": [\n            \"{ept_file}\",\n            {{\n                \"type\": \"filters.info\"\n            }}\n        ]\n    }}\n    \"\"\"\n\n    pipeline = pdal.Pipeline(pipeline_json)\n    pipeline.execute()\n    metadata = pipeline.metadata['metadata']\n    try:\n        min_x = metadata['filters.info']['bbox']['minx']\n        max_x = metadata['filters.info']['bbox']['maxx']\n        min_y = metadata['filters.info']['bbox']['miny']\n        max_y = metadata['filters.info']['bbox']['maxy']\n        return min_x, max_x, min_y, max_y\n    except KeyError:\n        raise KeyError(\"Bounds information is not available in the metadata.\")\n</code></pre>"},{"location":"api/process/#pyforestscan.process.process_with_tiles","title":"<code>process_with_tiles(ept_file, tile_size, output_path, metric, voxel_size, buffer_size=0.1, srs=None, hag=False, hag_dtm=False, dtm=None, bounds=None)</code>","text":"<p>Processes a large EPT point cloud by tiling, calculates CHM or other metrics for each tile, and writes the results to the specified output path.</p> <p>:param ept_file: Path to the EPT file containing the point cloud data. :param tile_size: Tuple (tile_width, tile_height) specifying the size of each tile. :param output_path: Directory where the output files will be saved. :param metric: Metric to compute (\"chm\", \"fhd\", or \"pai\"). :param voxel_size: Tuple specifying the voxel resolution (x_resolution, y_resolution, z_resolution). :param buffer_size: Fractional buffer size relative to tile size (e.g., 0.1 for 10% buffer). :param srs: Spatial reference system (optional). :param hag: Boolean indicating whether to compute Height Above Ground using Delaunay triangulation. :param hag_dtm: Boolean indicating whether to compute Height Above Ground using a provided DTM raster. :param dtm: Path to the DTM raster file (required if hag_dtm is True).</p> Source code in <code>pyforestscan/process.py</code> <pre><code>def process_with_tiles(ept_file, tile_size, output_path, metric, voxel_size, buffer_size=0.1, srs=None, hag=False,\n                       hag_dtm=False, dtm=None, bounds=None):\n    \"\"\"\n    Processes a large EPT point cloud by tiling, calculates CHM or other metrics for each tile,\n    and writes the results to the specified output path.\n\n    :param ept_file: Path to the EPT file containing the point cloud data.\n    :param tile_size: Tuple (tile_width, tile_height) specifying the size of each tile.\n    :param output_path: Directory where the output files will be saved.\n    :param metric: Metric to compute (\"chm\", \"fhd\", or \"pai\").\n    :param voxel_size: Tuple specifying the voxel resolution (x_resolution, y_resolution, z_resolution).\n    :param buffer_size: Fractional buffer size relative to tile size (e.g., 0.1 for 10% buffer).\n    :param srs: Spatial reference system (optional).\n    :param hag: Boolean indicating whether to compute Height Above Ground using Delaunay triangulation.\n    :param hag_dtm: Boolean indicating whether to compute Height Above Ground using a provided DTM raster.\n    :param dtm: Path to the DTM raster file (required if hag_dtm is True).\n    \"\"\"\n    min_x, max_x, min_y, max_y = get_bounds(ept_file)\n    num_tiles_x = int(np.ceil((max_x - min_x) / tile_size[0]))\n    num_tiles_y = int(np.ceil((max_y - min_y) / tile_size[1]))\n    total_tiles = num_tiles_x * num_tiles_y\n\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    with tqdm(total=total_tiles, desc=\"Processing tiles\") as pbar:\n        for i in range(num_tiles_x):\n            for j in range(num_tiles_y):\n                if metric == \"chm\":\n                    current_buffer_size = buffer_size\n                else:\n                    current_buffer_size = 0.0\n\n                buffer_x = current_buffer_size * tile_size[0]\n                buffer_y = current_buffer_size * tile_size[1]\n                tile_min_x = min_x + i * tile_size[0] - buffer_x\n                tile_max_x = min_x + (i + 1) * tile_size[0] + buffer_x\n                tile_min_y = min_y + j * tile_size[1] - buffer_y\n                tile_max_y = min_y + (j + 1) * tile_size[1] + buffer_y\n\n                tile_min_x = max(min_x, tile_min_x)\n                tile_max_x = min(max_x, tile_max_x)\n                tile_min_y = max(min_y, tile_min_y)\n                tile_max_y = min(max_y, tile_max_y)\n\n                if tile_max_x &lt;= tile_min_x or tile_max_y &lt;= tile_min_y:\n                    print(f\"Warning: Skipping tile ({i}, {j}) due to invalid spatial extent.\")\n                    pbar.update(1)\n                    continue\n\n                tile_pipeline_stages = [\n                    {\n                        \"type\": \"filters.crop\",\n                        \"bounds\": f\"([{tile_min_x},{tile_max_x}], [{tile_min_y},{tile_max_y}])\"\n                    }\n                ]\n\n                if hag:\n                    tile_pipeline_stages.append(_hag_delaunay())\n                elif hag_dtm:\n                    if not dtm or not os.path.isfile(dtm):\n                        raise FileNotFoundError(f\"DTM file is required for HAG calculation using DTM: {dtm}\")\n                    tile_pipeline_stages.append(_hag_raster(dtm))\n\n                base_pipeline = {\"type\": \"readers.ept\", \"filename\": ept_file}\n                if bounds:\n                    base_pipeline[\"bounds\"] = f\"{bounds}\"\n                tile_pipeline_json = {\n                    \"pipeline\": [base_pipeline] + tile_pipeline_stages\n                }\n\n                tile_pipeline = pdal.Pipeline(json.dumps(tile_pipeline_json))\n                tile_pipeline.execute()\n                tile_points = tile_pipeline.arrays[0]\n\n                if tile_points.size == 0:\n                    print(f\"Warning: No data in tile ({i}, {j}). Skipping.\")\n                    pbar.update(1)\n                    continue\n\n                buffer_pixels_x = int(np.ceil(buffer_x / voxel_size[0]))\n                buffer_pixels_y = int(np.ceil(buffer_y / voxel_size[1]))\n\n                if metric == \"chm\":\n                    chm, extent = calculate_chm(tile_points, voxel_size)\n\n                    if buffer_pixels_x * 2 &gt;= chm.shape[1] or buffer_pixels_y * 2 &gt;= chm.shape[0]:\n                        print(\n                            f\"Warning: Buffer size exceeds CHM dimensions for tile ({i}, {j}). Adjusting buffer size.\")\n                        buffer_pixels_x = max(0, chm.shape[1] // 2 - 1)\n                        buffer_pixels_y = max(0, chm.shape[0] // 2 - 1)\n\n                    chm = chm[buffer_pixels_y:-buffer_pixels_y, buffer_pixels_x:-buffer_pixels_x]\n\n                    core_extent = (\n                        tile_min_x + buffer_x,\n                        tile_max_x - buffer_x,\n                        tile_min_y + buffer_y,\n                        tile_max_y - buffer_y,\n                    )\n\n                    result_file = os.path.join(output_path, f\"tile_{i}_{j}_chm.tif\")\n                    create_geotiff(chm, result_file, srs, core_extent)\n                elif metric in [\"fhd\", \"pai\"]:\n                    voxels, spatial_extent = assign_voxels(tile_points, voxel_size)\n\n                    if metric == \"fhd\":\n                        result = calculate_fhd(voxels)\n                    elif metric == \"pai\":\n                        pad = calculate_pad(voxels, voxel_size[-1])\n\n                        if np.all(pad == 0):\n                            result = np.zeros((pad.shape[0], pad.shape[1]))\n                        else:\n                            result = calculate_pai(pad)\n                        result = np.where(np.isfinite(result), result, 0)\n\n                    if current_buffer_size &gt; 0:\n                        if buffer_pixels_x * 2 &gt;= result.shape[1] or buffer_pixels_y * 2 &gt;= result.shape[0]:\n                            print(\n                                f\"Warning: Buffer size exceeds {metric.upper()} dimensions for tile ({i}, {j}). Adjusting buffer size.\")\n                            buffer_pixels_x = max(0, result.shape[1] // 2 - 1)\n                            buffer_pixels_y = max(0, result.shape[0] // 2 - 1)\n\n                        result = result[buffer_pixels_y:-buffer_pixels_y, buffer_pixels_x:-buffer_pixels_x]\n\n                    core_extent = (\n                        tile_min_x + buffer_x,\n                        tile_max_x - buffer_x,\n                        tile_min_y + buffer_y,\n                        tile_max_y - buffer_y,\n                    )\n\n                    if core_extent[1] &lt;= core_extent[0] or core_extent[3] &lt;= core_extent[2]:\n                        print(f\"Warning: Invalid core extent for tile ({i}, {j}): {core_extent}. Skipping.\")\n                        pbar.update(1)\n                        continue\n\n                    result_file = os.path.join(output_path, f\"tile_{i}_{j}_{metric}.tif\")\n                    create_geotiff(result, result_file, srs, core_extent)\n                else:\n                    raise ValueError(f\"Unsupported metric: {metric}\")\n\n                pbar.update(1)\n</code></pre>"},{"location":"api/visualize/","title":"Visualize Module","text":""},{"location":"api/visualize/#pyforestscan.visualize.plot_2d","title":"<code>plot_2d(points, x_dim='X', y_dim='Z', color_map='viridis', alpha=1.0, point_size=1, fig_size=None)</code>","text":"<p>Plots a 2D scatter plot from a set of points with customizable dimensions, colors, and sizes.</p> <p>:param points: A DataFrame containing point data with dimensions and 'HeightAboveGround'. :type points: pandas.DataFrame :param x_dim: The dimension for the X-axis ('X', 'Y', 'Z', or 'HeightAboveGround'). :type x_dim: str :param y_dim: The dimension for the Y-axis ('X', 'Y', 'Z', or 'HeightAboveGround'). :type y_dim: str :param color_map: The colormap used to color the points according to 'HeightAboveGround'. :type color_map: str :param alpha: The transparency level of the points. :type alpha: float :param point_size: The size of each point in the scatter plot. :type point_size: float :param fig_size: The size of the figure as a tuple (width, height). If None, it is computed based on the aspect ratio. :type fig_size: tuple or None :return: None :rtype: None :raises ValueError: If the provided dimensions are not valid.</p> Source code in <code>pyforestscan/visualize.py</code> <pre><code>def plot_2d(points, x_dim='X', y_dim='Z', color_map='viridis', alpha=1.0, point_size=1, fig_size=None):\n    \"\"\"\n    Plots a 2D scatter plot from a set of points with customizable dimensions, colors, and sizes.\n\n    :param points: A DataFrame containing point data with dimensions and 'HeightAboveGround'.\n    :type points: pandas.DataFrame\n    :param x_dim: The dimension for the X-axis ('X', 'Y', 'Z', or 'HeightAboveGround').\n    :type x_dim: str\n    :param y_dim: The dimension for the Y-axis ('X', 'Y', 'Z', or 'HeightAboveGround').\n    :type y_dim: str\n    :param color_map: The colormap used to color the points according to 'HeightAboveGround'.\n    :type color_map: str\n    :param alpha: The transparency level of the points.\n    :type alpha: float\n    :param point_size: The size of each point in the scatter plot.\n    :type point_size: float\n    :param fig_size: The size of the figure as a tuple (width, height). If None, it is computed based on the aspect ratio.\n    :type fig_size: tuple or None\n    :return: None\n    :rtype: None\n    :raises ValueError: If the provided dimensions are not valid.\n    \"\"\"\n    valid_dims = ['X', 'Y', 'Z', 'HeightAboveGround']\n    if x_dim not in valid_dims or y_dim not in valid_dims:\n        raise ValueError(f\"Invalid dimensions. Choose from: {valid_dims}\")\n\n    x = points[x_dim]\n    y = points[y_dim]\n    colors = points['HeightAboveGround']\n\n    if fig_size is None:\n        aspect_ratio = (np.max(x) - np.min(x)) / (np.max(y) - np.min(y))\n        fig_size = (10 * aspect_ratio, 10)\n\n        max_fig_size = 20  # inches\n        if max(fig_size) &gt; max_fig_size:\n            scale_factor = max_fig_size / max(fig_size)\n            fig_size = (fig_size[0] * scale_factor, fig_size[1] * scale_factor)\n\n    plt.figure(figsize=fig_size)\n\n    plt.scatter(x, y, c=colors, cmap=color_map, alpha=alpha, s=point_size)\n    plt.xlabel(x_dim)\n    plt.ylabel(y_dim)\n    plt.title(f'{x_dim} vs {y_dim} Colored by Height Above Ground')\n    plt.colorbar(label='Height Above Ground (m)')\n    plt.show()\n</code></pre>"},{"location":"api/visualize/#pyforestscan.visualize.plot_metric","title":"<code>plot_metric(title, metric, extent, metric_name=None, cmap='viridis', fig_size=None)</code>","text":"<p>Plots a given metric using the provided data and configuration.</p> <p>:param title: string     The name of the metric to be plotted :param metric: ndarray     2D array representing the metric's values. :param extent: list     List of four elements [xmin, xmax, ymin, ymax] defining the extent of the plot. :param metric_name: string, optional     Label to be used for the colorbar. If None, the title is used as the     metric name. This is useful for specifying units or a more detailed     description of the metric. :param cmap: str, optional     Colormap to be used for the plot. Default is 'viridis'. :param fig_size: tuple, optional     Tuple specifying the size of the figure (width, height). Default is calculated based on the extent. :return: None :rtype: None</p> Source code in <code>pyforestscan/visualize.py</code> <pre><code>def plot_metric(title, metric, extent, metric_name=None, cmap='viridis', fig_size=None):\n    \"\"\"\n    Plots a given metric using the provided data and configuration.\n\n    :param title: string\n        The name of the metric to be plotted\n    :param metric: ndarray\n        2D array representing the metric's values.\n    :param extent: list\n        List of four elements [xmin, xmax, ymin, ymax] defining the extent of the plot.\n    :param metric_name: string, optional\n        Label to be used for the colorbar. If None, the title is used as the\n        metric name. This is useful for specifying units or a more detailed\n        description of the metric.\n    :param cmap: str, optional\n        Colormap to be used for the plot. Default is 'viridis'.\n    :param fig_size: tuple, optional\n        Tuple specifying the size of the figure (width, height). Default is calculated based on the extent.\n    :return: None\n    :rtype: None\n    \"\"\"\n    if metric_name is None:\n        metric_name = title\n    if fig_size is None:\n        x_range = extent[1] - extent[0]\n        y_range = extent[3] - extent[2]\n        aspect_ratio = x_range / y_range\n        fig_size = (10 * aspect_ratio, 10)\n\n        max_fig_size = 20\n        if max(fig_size) &gt; max_fig_size:\n            scale_factor = max_fig_size / max(fig_size)\n            fig_size = (fig_size[0] * scale_factor, fig_size[1] * scale_factor)\n\n    plt.figure(figsize=fig_size)\n\n    plt.imshow(metric.T, extent=extent, cmap=cmap)\n    plt.colorbar(label=metric_name)\n    plt.title(title)\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.show()\n</code></pre>"},{"location":"api/visualize/#pyforestscan.visualize.plot_pad","title":"<code>plot_pad(pad, slice_index, axis='x', cmap='viridis', hag_values=None, horizontal_values=None)</code>","text":"<p>Plots a 2D slice of Plant Area Density (PAD) data with dZ HAG on the Y-axis.</p> <p>:param pad: numpy.ndarray     The 3D Plant Area Density data with shape (X, Y, HAG). :param slice_index: int     The index of the slice to be plotted along the specified axis. :param axis: str, optional     The axis along which to slice the data. Default is 'x'. Choose from 'x', 'y'. :param cmap: str, optional     The colormap to be used for plotting. Default is 'viridis'. :param hag_values: numpy.ndarray, optional     Array of HAG (Height Above Ground) values corresponding to the third dimension.     If None, will use indices. :param horizontal_values: numpy.ndarray, optional     Array of horizontal (X or Y) values corresponding to the first or second dimension.     If None, will use indices. :raises ValueError: If an invalid axis is provided or slice_index is out of bounds. :return: None :rtype: None</p> Source code in <code>pyforestscan/visualize.py</code> <pre><code>def plot_pad(pad, slice_index, axis='x', cmap='viridis', hag_values=None, horizontal_values=None):\n    \"\"\"\n    Plots a 2D slice of Plant Area Density (PAD) data with dZ HAG on the Y-axis.\n\n    :param pad: numpy.ndarray\n        The 3D Plant Area Density data with shape (X, Y, HAG).\n    :param slice_index: int\n        The index of the slice to be plotted along the specified axis.\n    :param axis: str, optional\n        The axis along which to slice the data. Default is 'x'. Choose from 'x', 'y'.\n    :param cmap: str, optional\n        The colormap to be used for plotting. Default is 'viridis'.\n    :param hag_values: numpy.ndarray, optional\n        Array of HAG (Height Above Ground) values corresponding to the third dimension.\n        If None, will use indices.\n    :param horizontal_values: numpy.ndarray, optional\n        Array of horizontal (X or Y) values corresponding to the first or second dimension.\n        If None, will use indices.\n    :raises ValueError: If an invalid axis is provided or slice_index is out of bounds.\n    :return: None\n    :rtype: None\n    \"\"\"\n    # Validate the axis parameter\n    if axis not in ['x', 'y']:\n        raise ValueError(f\"Invalid axis: '{axis}'. Choose from 'x' or 'y'.\")\n\n    if axis == 'x':\n        if slice_index &lt; 0 or slice_index &gt;= pad.shape[0]:\n            raise ValueError(f\"slice_index {slice_index} out of range for axis 'x' with size {pad.shape[0]}\")\n        pad_2d = pad[slice_index, :, :]\n        horizontal_axis_label = 'Y'\n        horizontal_axis_values = horizontal_values if horizontal_values is not None else np.arange(pad.shape[1])\n    else:  # axis == 'y'\n        if slice_index &lt; 0 or slice_index &gt;= pad.shape[1]:\n            raise ValueError(f\"slice_index {slice_index} out of range for axis 'y' with size {pad.shape[1]}\")\n        pad_2d = pad[:, slice_index, :]\n        horizontal_axis_label = 'X'\n        horizontal_axis_values = horizontal_values if horizontal_values is not None else np.arange(pad.shape[0])\n\n    hag_values = hag_values if hag_values is not None else np.arange(pad.shape[2])\n\n    pad_2d = pad_2d.T\n\n    if horizontal_values is not None:\n        if axis == 'x' and len(horizontal_values) != pad.shape[1]:\n            raise ValueError(\"Length of horizontal_values does not match the Y dimension of pad.\")\n        if axis == 'y' and len(horizontal_values) != pad.shape[0]:\n            raise ValueError(\"Length of horizontal_values does not match the X dimension of pad.\")\n    else:\n        horizontal_axis_values = np.arange(pad.shape[1]) if axis == 'x' else np.arange(pad.shape[0])\n\n    plt.figure(figsize=(10, 6))\n    img = plt.imshow(\n        pad_2d,\n        cmap=cmap,\n        origin='lower',\n        extent=(\n            horizontal_axis_values.min(),\n            horizontal_axis_values.max(),\n            hag_values.min(),\n            hag_values.max()\n        ),\n        aspect='auto'\n    )\n    plt.colorbar(img, label='PAD')\n    plt.title(f'Plant Area Density (PAD) - {horizontal_axis_label} vs dZ at Slice {slice_index}')\n    plt.xlabel(horizontal_axis_label)\n    plt.ylabel('dZ')\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"examples/calculate-forest-metrics/","title":"Calculate forest metrics","text":"In\u00a0[2]: Copied! <pre>from pyforestscan.handlers import read_lidar, create_geotiff\nfrom pyforestscan.visualize import plot_pad, plot_metric\nfrom pyforestscan.filters import filter_hag\nfrom pyforestscan.calculate import generate_dtm, assign_voxels, calculate_pad, calculate_pai, calculate_fhd, calculate_chm\n</pre> from pyforestscan.handlers import read_lidar, create_geotiff from pyforestscan.visualize import plot_pad, plot_metric from pyforestscan.filters import filter_hag from pyforestscan.calculate import generate_dtm, assign_voxels, calculate_pad, calculate_pai, calculate_fhd, calculate_chm In\u00a0[3]: Copied! <pre>file_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\n</pre> file_path = \"../example_data/20191210_5QKB020880.laz\" arrays = read_lidar(file_path, \"EPSG:32605\", hag=True) <p>Next, we will use <code>filter_hag()</code> to remove any points below ground.</p> In\u00a0[4]: Copied! <pre>arrays = filter_hag(arrays)\npoints = arrays[0]\n</pre> arrays = filter_hag(arrays) points = arrays[0] In\u00a0[5]: Copied! <pre>voxel_resolution = (5, 5, 1) \nvoxels, extent = assign_voxels(points, voxel_resolution)\n</pre> voxel_resolution = (5, 5, 1)  voxels, extent = assign_voxels(points, voxel_resolution) In\u00a0[7]: Copied! <pre>chm, extent = calculate_chm(points, voxel_resolution)\n</pre> chm, extent = calculate_chm(points, voxel_resolution) In\u00a0[8]: Copied! <pre>plot_metric('Canopy Height Model', chm, extent, metric_name='Height (m)', cmap='viridis', fig_size=None)\n</pre> plot_metric('Canopy Height Model', chm, extent, metric_name='Height (m)', cmap='viridis', fig_size=None) In\u00a0[9]: Copied! <pre>pad = calculate_pad(voxels, voxel_resolution[-1])\n</pre> pad = calculate_pad(voxels, voxel_resolution[-1]) In\u00a0[11]: Copied! <pre>plot_pad(pad, 5, axis='y', cmap='viridis')\n</pre> plot_pad(pad, 5, axis='y', cmap='viridis') In\u00a0[13]: Copied! <pre>pai = calculate_pai(pad)\n</pre> pai = calculate_pai(pad) In\u00a0[14]: Copied! <pre>plot_metric('Plant Area Index', pai, extent, metric_name='PAI', cmap='viridis', fig_size=None)\n</pre> plot_metric('Plant Area Index', pai, extent, metric_name='PAI', cmap='viridis', fig_size=None) In\u00a0[15]: Copied! <pre>fhd = calculate_fhd(voxels)\n</pre> fhd = calculate_fhd(voxels) In\u00a0[17]: Copied! <pre>plot_metric('Foliage Height Diversity', fhd, extent, metric_name='FHD', cmap='viridis', fig_size=None)\n</pre> plot_metric('Foliage Height Diversity', fhd, extent, metric_name='FHD', cmap='viridis', fig_size=None)"},{"location":"examples/calculate-forest-metrics/#calculating-forest-metrics","title":"Calculating Forest Metrics\u00b6","text":"<p>This notebook will explain how to calculate and visualize forest metrics. Code snippets for how to get started using PyForestScan can be found in the notebook getting-started-importing-preprocessing-dtm-chm, and in the documentation.</p> <p>The example dataset is a one-square-kilometer tile derived from a 2019 aerial LiDAR survey of the Big Island of Hawaii. The data is captured over a dry forest and has a nominal pulse spacing of 0.35 meters. The data has been preprocessed to classify ground and vegetation points.</p> <p>First we will load the <code>pyforestscan</code> functions that will be used.</p>"},{"location":"examples/calculate-forest-metrics/#import-data","title":"Import Data\u00b6","text":"<p>We will begin by importing and preprocessing the data. It is important for a <code>HeightAboveGround</code> dimension to be defined, which can be accomplished by setting <code>hag=True</code> when importing data.</p>"},{"location":"examples/calculate-forest-metrics/#create-voxels","title":"Create Voxels\u00b6","text":"<p>We need to create voxels, and assign points to them. Voxel resolution must be given as a tuple with the format <code>(x_res, y_res, z_res)</code> where <code>x_res</code>, <code>y_res</code>, and <code>z_res</code> are the resolutions along the x, y, and z axes. Points within voxel bounds are assigned to them.</p>"},{"location":"examples/calculate-forest-metrics/#calculate-forest-metrics","title":"Calculate Forest Metrics\u00b6","text":""},{"location":"examples/calculate-forest-metrics/#canopy-height-model","title":"Canopy Height Model\u00b6","text":"<p>We will calculate and plot a canopy height model (CHM), showing the highest point above ground in each voxel column. <code>calculate_chm</code> will return the canopy height model along with its extent. Forest metrics are calculated in the same units as the data. In this case, since the data is in EPSG:32605, output will be in meters.</p>"},{"location":"examples/calculate-forest-metrics/#plant-area-density","title":"Plant Area Density\u00b6","text":"<p>Next we will calculate and plot plant area density (PAD), which shows density of plant matter within each voxel.</p>"},{"location":"examples/calculate-forest-metrics/#plant-area-index","title":"Plant Area Index\u00b6","text":"<p>You can calculate and plot plant area index (PAI), which quantifies the total plant surface area of above-ground plant matter (leaves, branches, and stems) per unit of ground area, which corresponds to the vertical summation of PAD.</p>"},{"location":"examples/calculate-forest-metrics/#foliage-height-diversity","title":"Foliage Height Diversity\u00b6","text":"<p>We can calculate foliage height diversity (FHD). FHD is a measure of how plant material is distributed across the vertical layers of a canopy, as calculated using Shannon entropy.</p>"},{"location":"examples/getting-started-importing-preprocessing-dtm-chm/","title":"Getting started importing preprocessing dtm chm","text":"In\u00a0[5]: Copied! <pre>from pyforestscan.handlers import read_lidar, create_geotiff\nfrom pyforestscan.visualize import plot_2d, plot_metric, plot_2d\nfrom pyforestscan.filters import filter_hag, remove_outliers_and_clean, classify_ground_points, filter_select_ground\nfrom pyforestscan.calculate import generate_dtm, assign_voxels, calculate_chm\n</pre> from pyforestscan.handlers import read_lidar, create_geotiff from pyforestscan.visualize import plot_2d, plot_metric, plot_2d from pyforestscan.filters import filter_hag, remove_outliers_and_clean, classify_ground_points, filter_select_ground from pyforestscan.calculate import generate_dtm, assign_voxels, calculate_chm In\u00a0[2]: Copied! <pre>file_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\")\n</pre> file_path = \"../example_data/20191210_5QKB020880.laz\" arrays = read_lidar(file_path, \"EPSG:32605\") <p>Now that the data has been loaded, we can clean the data by removing outliers and classifying ground points.</p> In\u00a0[3]: Copied! <pre>cleaned_arrays = remove_outliers_and_clean(arrays, mean_k=8, multiplier=3.0)\nclassified_arrays = classify_ground_points(cleaned_arrays)\n</pre> cleaned_arrays = remove_outliers_and_clean(arrays, mean_k=8, multiplier=3.0) classified_arrays = classify_ground_points(cleaned_arrays) In\u00a0[6]: Copied! <pre>ground_points = filter_select_ground(classified_arrays)\ndtm, extent = generate_dtm(ground_points, resolution=10.0)\n</pre> ground_points = filter_select_ground(classified_arrays) dtm, extent = generate_dtm(ground_points, resolution=10.0) <p>The DTM can be exported as a geotiff which can then be opened in a GIS for further analysis.</p> In\u00a0[7]: Copied! <pre>create_geotiff(dtm, \"../example_data/20191210_5QKB020880_DS05_dtm.tif\", \"EPSG:32605\", extent)\n</pre> create_geotiff(dtm, \"../example_data/20191210_5QKB020880_DS05_dtm.tif\", \"EPSG:32605\", extent) <p>We can also visualize this DTM using the <code>plot_metric</code> function.</p> In\u00a0[8]: Copied! <pre>plot_metric('Digital Terrain Model', dtm, extent, metric_name='Elevation (m)',cmap='viridis', fig_size=None)\n</pre> plot_metric('Digital Terrain Model', dtm, extent, metric_name='Elevation (m)',cmap='viridis', fig_size=None) In\u00a0[10]: Copied! <pre>arrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\n</pre> arrays = read_lidar(file_path, \"EPSG:32605\", hag=True) In\u00a0[11]: Copied! <pre>chm, extent = calculate_chm(arrays[0], (1,1,1))\n</pre> chm, extent = calculate_chm(arrays[0], (1,1,1)) <p>Ploting and export can be accomplished the same way as DTMs.</p> In\u00a0[12]: Copied! <pre>create_geotiff(chm, \"../example_data/20191210_5QKB020880_DS05_chm.tif\", \"EPSG:32605\", extent)\n</pre> create_geotiff(chm, \"../example_data/20191210_5QKB020880_DS05_chm.tif\", \"EPSG:32605\", extent) In\u00a0[13]: Copied! <pre>plot_metric(\"Canopy Height Model\", chm, extent, metric_name='Height (m)', cmap='viridis', fig_size=None)\n</pre> plot_metric(\"Canopy Height Model\", chm, extent, metric_name='Height (m)', cmap='viridis', fig_size=None)"},{"location":"examples/getting-started-importing-preprocessing-dtm-chm/#getting-started-importing-preprocessing-dtms-and-chms","title":"Getting Started: Importing, Preprocessing, DTMs and CHMs\u00b6","text":"<p>This notebook will explain how to load and run some of the basic functions to import and process data, create a digital terrain model, a canopy height model, and visualize and export results. Code snippets for more functions can be found in the calculate-forest-metrics notebook, and in the documentation.</p> <p>The example dataset is a one-square-kilometer tile derived from a 2019 aerial lidar survey of the Big Island of Hawaii. The data is captured over a dry forest and has a nominal pulse spacing of 0.35 meters. The data has been preprocessed to classify ground and vegetation points.</p> <p>First we will load the <code>pyforestscan</code> functions that will be used.</p>"},{"location":"examples/getting-started-importing-preprocessing-dtm-chm/#importing-and-preprocessing-the-data","title":"Importing and Preprocessing the Data\u00b6","text":"<p>We will create a digital terrain model (DTM). We will begin by importing and cleaning the data. For this example, we will act as if the data has not been preprocessed to classify ground.</p> <p>We will read the lidar data:</p>"},{"location":"examples/getting-started-importing-preprocessing-dtm-chm/#creating-a-dtm","title":"Creating a DTM\u00b6","text":"<p>To create a DTM, we will begin by extracting only the ground points. Then we can use those ground points to generate the DTM.</p>"},{"location":"examples/getting-started-importing-preprocessing-dtm-chm/#creating-a-chm","title":"Creating a CHM\u00b6","text":"<p>Next we will create a canopy height model (CHM) from a point cloud array. This array must have a HeightAboveGround dimension defined. This can be added easily when importing the data by setting <code>hag=True</code>. In addition to your point cloud array, you must also define the resolution. The resolution must be given as a tuple with the format <code>(x_res, y_res, z_res)</code> where <code>x_res</code>, <code>y_res</code>, and <code>z_res</code> are the resolutions along the x, y, and z axes. <code>calculate_chm</code> will return the canopy height model along with its extent.</p>"},{"location":"examples/working-with-large-point-clouds/","title":"Working with large point clouds","text":"In\u00a0[1]: Copied! <pre>import geopandas as gpd\nimport numpy as np\n\nfrom pyforestscan.handlers import read_lidar, create_geotiff, write_las\nfrom pyforestscan.visualize import plot_metric, plot_2d\nfrom pyforestscan.calculate import assign_voxels, calculate_pad, calculate_pai, calculate_fhd, calculate_chm\nfrom pyforestscan.process import process_with_tiles\n</pre> import geopandas as gpd import numpy as np  from pyforestscan.handlers import read_lidar, create_geotiff, write_las from pyforestscan.visualize import plot_metric, plot_2d from pyforestscan.calculate import assign_voxels, calculate_pad, calculate_pai, calculate_fhd, calculate_chm from pyforestscan.process import process_with_tiles In\u00a0[5]: Copied! <pre>bounds = ([202000.000, 203000.000], [2187999.980, 2189000.000])\nept = \"../example_data/ept/ept.json\"\nept_srs = \"EPSG:32605\"\npointclouds = read_lidar(ept, ept_srs, bounds, hag=True)\n</pre> bounds = ([202000.000, 203000.000], [2187999.980, 2189000.000]) ept = \"../example_data/ept/ept.json\" ept_srs = \"EPSG:32605\" pointclouds = read_lidar(ept, ept_srs, bounds, hag=True) <p>Once the file is read, we can build the voxels and calculate forest metrics:</p> In\u00a0[6]: Copied! <pre>voxel_resolution = (5, 5, 1) \nvoxels, extent = assign_voxels(pointclouds[0], voxel_resolution)\n</pre> voxel_resolution = (5, 5, 1)  voxels, extent = assign_voxels(pointclouds[0], voxel_resolution) In\u00a0[7]: Copied! <pre>pad = calculate_pad(voxels, voxel_resolution[-1])\npai = calculate_pai(pad)\n</pre> pad = calculate_pad(voxels, voxel_resolution[-1]) pai = calculate_pai(pad) In\u00a0[8]: Copied! <pre>plot_metric(\"Plant Area Index\", pai, extent, metric_name='Plant Area Index', cmap='viridis', fig_size=None)\n</pre> plot_metric(\"Plant Area Index\", pai, extent, metric_name='Plant Area Index', cmap='viridis', fig_size=None) In\u00a0[10]: Copied! <pre>bounds = ([202000.000, 205000.000], [2186999.980, 2190000.000])\nprocess_with_tiles(\n    ept, \n    (1000, 1000), \n    \"../example_data/tiles\", \n    \"pai\", \n    (5, 5, 1), \n    buffer_size=0.15,\n    srs=\"EPSG:32605\",\n    bounds=bounds,\n    hag=True\n)\n</pre> bounds = ([202000.000, 205000.000], [2186999.980, 2190000.000]) process_with_tiles(     ept,      (1000, 1000),      \"../example_data/tiles\",      \"pai\",      (5, 5, 1),      buffer_size=0.15,     srs=\"EPSG:32605\",     bounds=bounds,     hag=True ) <pre>Processing tiles: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:49&lt;00:00, 12.45s/it]</pre> <pre>Warning: No data in tile (1, 1). Skipping.\n</pre> <pre>\n</pre> <p>And we can plot this geotiff using rasterio or load it into a GIS.</p> In\u00a0[12]: Copied! <pre>import rasterio\nimport matplotlib.pyplot as plt\n\ntif_path = \"../example_data/tiles/tile_0_0_pai.tif\"\n\nwith rasterio.open(tif_path) as src:\n    raster = src.read(1)\n    metadata = src.meta\n\nplt.figure(figsize=(10, 8))\nplt.imshow(raster, cmap='viridis')\nplt.colorbar(label=\"Values\")\nplt.title(\"Raster Plot\")\nplt.xlabel(\"Column Index\")\nplt.ylabel(\"Row Index\")\nplt.show()\n</pre> import rasterio import matplotlib.pyplot as plt  tif_path = \"../example_data/tiles/tile_0_0_pai.tif\"  with rasterio.open(tif_path) as src:     raster = src.read(1)     metadata = src.meta  plt.figure(figsize=(10, 8)) plt.imshow(raster, cmap='viridis') plt.colorbar(label=\"Values\") plt.title(\"Raster Plot\") plt.xlabel(\"Column Index\") plt.ylabel(\"Row Index\") plt.show() In\u00a0[20]: Copied! <pre>crowns = gpd.read_file(\"../example_data/test_segment.gpkg\")\ncrown_geom = crowns.geometry.iloc[0]\nminx, miny, maxx, maxy = crown_geom.bounds\nbounds = ([minx, maxx], [miny, maxy])\npointclouds = read_lidar(ept, ept_srs, bounds, crop_poly=True, poly=crown_geom.wkt)\n</pre> crowns = gpd.read_file(\"../example_data/test_segment.gpkg\") crown_geom = crowns.geometry.iloc[0] minx, miny, maxx, maxy = crown_geom.bounds bounds = ([minx, maxx], [miny, maxy]) pointclouds = read_lidar(ept, ept_srs, bounds, crop_poly=True, poly=crown_geom.wkt) <p>Now to plot with points colored by height above ground:</p> In\u00a0[23]: Copied! <pre>plot_2d(pointclouds[0], x_dim='X', y_dim='Z', alpha=0.5, point_size=50, fig_size=(10, 10))\n</pre> plot_2d(pointclouds[0], x_dim='X', y_dim='Z', alpha=0.5, point_size=50, fig_size=(10, 10)) <p>And we can calculate metrics for the tree by setting the voxel size to be that of the bounds of the clipped point:</p> In\u00a0[18]: Copied! <pre>voxel_resolution = (maxx - minx, maxy - miny, 1) \nvoxels, extent = assign_voxels(pointclouds[0], voxel_resolution)\ncanopy_height, extent = calculate_chm(pointclouds[0], voxel_resolution)\npad = calculate_pad(voxels, voxel_resolution[-1])\npai = calculate_pai(pad)\nfhd = calculate_fhd(voxels)\nprint(\"canopy height:\", canopy_height)\nprint(\"plant area index:\", pai)\nprint(\"foliage height diversity:\", fhd)\n</pre> voxel_resolution = (maxx - minx, maxy - miny, 1)  voxels, extent = assign_voxels(pointclouds[0], voxel_resolution) canopy_height, extent = calculate_chm(pointclouds[0], voxel_resolution) pad = calculate_pad(voxels, voxel_resolution[-1]) pai = calculate_pai(pad) fhd = calculate_fhd(voxels) print(\"canopy height:\", canopy_height) print(\"plant area index:\", pai) print(\"foliage height diversity:\", fhd)"},{"location":"examples/working-with-large-point-clouds/#working-with-large-point-clouds","title":"Working with Large Point Clouds\u00b6","text":"<p>This notebook will explain how use PyForestScan with large data sets. Code snippets for how to get started using PyForestScan or calculate key forest metrics can be found in the notebooks getting-started-importing-preprocessing-dtm-chm or calculate-forest-metrics, and in the documentation.</p> <p>We will use a larger section of our example data set. This section contains 2.35 billion points (20GB) with a nominal pulse spacing of 0.35 meters covering the Puuwaawaa reigion of the Big Island of Hawaii. The vegetation here is dry forest and we will clip to the same region as our other examples. This data is currently not available online but will be hosted soon on AWS. EPT data can be read directly from a URL or can be stored and read locally (it is faster to read locally).</p> <p>First we will load the necessary python packages and functions.</p>"},{"location":"examples/working-with-large-point-clouds/#import-data","title":"Import Data\u00b6","text":"<p>PyForestScan leverages PDAL and Entwine to read EPT and COPC data formats. EPT and COPC are optimized for handling very large point clouds and have spatial knowlege of the data, allowing us to access metadata for the entire dataset while working with extracts. We will use this to extract only points that fit within the one kilometer tile that we explored in the other examples.</p>"},{"location":"examples/working-with-large-point-clouds/#creating-tiled-metrics","title":"Creating Tiled Metrics\u00b6","text":"<p>We can also read the ept file to create tiles of a given size for a given. In this example, we will read from the same EPT file to create 1000m by 1000m tiles of PAI over a larger area. It will write these tiles to a directory as geotiff files. This EPT dataset already has HeightAboveGround and so we can skip the <code>hag=True</code> argument. This will save on loading time.</p>"},{"location":"examples/working-with-large-point-clouds/#reading-and-clipping-to-polygons","title":"Reading and Clipping to Polygons\u00b6","text":"<p>We can also read from a large point cloud and only load the points clipped to polygons by making use of the read EPT capabilities and the ability to clip to polygons. This will also allow us to read points that belong to a single and calculate these metrics at the tree level. For example, we can calculate the PAI and FHD for a given tree.</p>"},{"location":"usage/digital-terrain-models/","title":"Digital Terrain Models","text":"<p>Given a classified point cloud, pyforestscan can create, save, and visualize digital terrain models (DTMs) as geotiffs:</p> <pre><code>from pyforestscan.calculate import generate_dtm\nfrom pyforestscan.filters import filter_select_ground\nfrom pyforestscan.handlers import create_geotiff\nfrom pyforestscan.visualize import plot_metric\n\nground_points = filter_select_ground(classified_arrays)\n\ndtm, extent = generate_dtm(ground_points, resolution=10.0)\n\ncreate_geotiff(dtm, \"../example_data/20191210_5QKB020880_DS05_dtm.tif\", \"EPSG:32605\", extent)\n\nplot_metric('Digital Terrain Model', dtm, extent, metric_name='Elevation (m)', cmap='viridis', fig_size=None)\n</code></pre> <p></p>"},{"location":"usage/getting-started-import-and-preprocess/","title":"Importing, Preprocessing, and Writing Data","text":"<p>To use pyforestscan, first import it in your Python project:</p> <pre><code>import pyforestscan\n</code></pre> <p>Then, you can use it to load point cloud data and extract forest structure metrics. </p> <p>The following sections will provide an overview of usage of the major functions of pyforestscan. For a complete reference of all functions in pyforestscan, please check the API documentation. For comprehensive examples of these functions, please see the example jupyter notebooks. </p>"},{"location":"usage/getting-started-import-and-preprocess/#importing-point-cloud-data","title":"Importing Point Cloud Data","text":"<p>pyforestscan supports reading from the following point cloud data formats:</p> <ul> <li>las</li> <li>laz</li> <li>copc</li> <li>ept</li> </ul> <p>and reading point clouds is done using the <code>read_lidar</code> function:</p> <pre><code>from pyforestscan.handlers import read_lidar\n\nfile_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\npointcloud = arrays[0]\n</code></pre>"},{"location":"usage/getting-started-import-and-preprocess/#preprocessing-point-cloud-data","title":"Preprocessing Point Cloud Data","text":"<p>pyforestscan provides some basic functionality to help preprocess point cloud data. Many of these functions are wrapped PDAL routines. For example, to remove outliers and classify ground points:</p> <pre><code>from pyforestscan.filters import remove_outliers_and_clean, classify_ground_points\n\ncleaned_arrays = remove_outliers_and_clean(arrays, mean_k=8, multiplier=3.0)\nclassified_arrays = classify_ground_points(cleaned_arrays)\n</code></pre>"},{"location":"usage/getting-started-import-and-preprocess/#exporting-point-clouds","title":"Exporting Point Clouds","text":"<p>pyforestscan supports exporting processed point clouds to las and laz formats. To export a point cloud as a LAZ file:</p> <pre><code>from pyforestscan.handlers import write_las\n\nwrite_las(classified_arrays, \"/path/to/exported_file.las\", srs=\"EPSG:32605\", compress=True)\n</code></pre>"},{"location":"usage/forest-structure/chm/","title":"Canopy Height Models (CHM)","text":""},{"location":"usage/forest-structure/chm/#theory","title":"Theory","text":"<p>Canopy height is given as the maximum height above ground for a point within each grid cell or for all points within a given polygon.</p> \\[ H_{\\text{canopy}} = \\max(HAG_{\\text{points}}) \\] <p>Where:</p> <ul> <li>\\( H_{\\text{canopy}} \\) is the canopy height for the grid cell or polygon.</li> <li>\\( HAG_{\\text{points}} \\) represents the set of heights above ground of all points within a given grid cell or polygon.</li> </ul>"},{"location":"usage/forest-structure/chm/#calculating-chm","title":"Calculating CHM","text":"<p>To calculate canopy height and generate a canopy height model:</p> <pre><code>from pyforestscan.handlers import read_lidar\nfrom pyforestscan.visualize import plot_metric\nfrom pyforestscan.calculate import calculate_chm\n\nfile_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\nchm, extent = calculate_chm(arrays[0], (1,1,1))\nplot_metric(\"Canopy Height Model\", chm, extent, metric_name='Height (m)', cmap='viridis', fig_size=None)\n</code></pre> <p></p>"},{"location":"usage/forest-structure/chm/#gridded-chm","title":"Gridded CHM","text":"<p>PyForestScan uses PDAL and Entwine to read and process large files stored in the EPT format. These can be used to create gridded metrics, like CHM. To create a 1km grid of CHM:</p> <pre><code>from pyforestscan.process import process_with_tiles\n\nept = \"../example_data/ept/ept.json\"\nept_srs = \"EPSG:32605\"\n\nprocess_with_tiles(\n    ept, \n    (1000, 1000), \n    \"../example_data/tiles\", \n    \"chm\", \n    (5, 5, 1), \n    buffer_size=0.15,\n    srs=\"EPSG:32605\"\n)\n</code></pre> <p>If the EPT covers a very large area and the gridded metrics should only cover a fraction of that area, you can provide the tile processor with the bounds of the region that you want to tile:</p> <pre><code>bounds = ([202000.000, 205000.000], [2186999.980, 2190000.000])\nprocess_with_tiles(\n    ept, \n    (1000, 1000), \n    \"../example_data/tiles\", \n    \"pai\", \n    (5, 5, 1), \n    buffer_size=0.15,\n    srs=\"EPSG:32605\",\n    bounds=bounds\n)\n</code></pre>"},{"location":"usage/forest-structure/chm/#canopy-height-for-abstract-polygons","title":"Canopy Height for Abstract Polygons","text":"<p>It is also possible to read a point cloud and clip it to a polygon in order to extract metrics for that region clipped by the polygon. For example, with the polygon of a tree, we can clip the points to that tree and extact the canopy height:</p> <p><pre><code>import geopandas as gpd\nfrom pyforestscan.handlers import read_lidar\nfrom pyforestscan.visualize import plot_2d\n\nept = \"../example_data/ept/ept.json\"\nept_srs = \"EPSG:32605\"\n\ncrowns = gpd.read_file(\"../example_data/test_segment.gpkg\")\ncrown_geom = crowns.geometry.iloc[0]\nminx, miny, maxx, maxy = crown_geom.bounds\nbounds = ([minx, maxx], [miny, maxy])\npointclouds = read_lidar(ept, ept_srs, bounds, crop_poly=True, poly=crown_geom.wkt)\nplot_2d(pointclouds[0], x_dim='X', y_dim='Z', alpha=0.5, point_size=50, fig_size=(10, 10))\n</code></pre> </p>"},{"location":"usage/forest-structure/fhd/","title":"Foliage Height Diversity (FHD)","text":""},{"location":"usage/forest-structure/fhd/#theory","title":"Theory","text":"<p>Foliage Height Diversity (FHD) is a metric that quantifies the vertical distribution of plant material in the forest canopy. It is based on Shannon entropy and calculated using methods derived from Hurlbert (1971) and MacArthur &amp; MacArthur (1961).</p> \\[ FHD = - \\sum_{i=1}^{n} p_i \\ln(p_i) \\] <p>Where: -   \\( FHD \\) is the Foliage Height Diversity. -   \\( p_i \\) is the proportion of total plant material in voxel \\( i \\) relative to the entire vertical column. -   \\( n \\) is the number of vertical layers in the canopy.</p> <p>FHD provides an indication of how plant material is distributed vertically, with higher values suggesting a more even distribution of foliage across different height levels.</p>"},{"location":"usage/forest-structure/fhd/#calculating-fhd","title":"Calculating FHD","text":"<p>To calculate FHD:</p> <pre><code>from pyforestscan.handlers import read_lidar\nfrom pyforestscan.visualize import plot_metric\nfrom pyforestscan.filters import filter_hag\nfrom pyforestscan.calculate import assign_voxels, calculate_fhd\n\nfile_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\narrays = filter_hag(arrays)\npoints = arrays[0]\n\nvoxel_resolution = (5, 5, 1) \nvoxels, extent = assign_voxels(points, voxel_resolution)\n\nfhd = calculate_fhd(voxels)\nplot_metric('Foliage Height Diversity', fhd, extent, metric_name='FHD', cmap='viridis', fig_size=None)\n</code></pre> <p></p>"},{"location":"usage/forest-structure/fhd/#references","title":"References","text":"<p>Hurlbert, Stuart H. 1971. \"The Nonconcept of Species Diversity: A Critique and Alternative Parameters.\" Ecology 52 (4): 577--86. https://doi.org/10.2307/1934145.</p> <p>MacArthur, Robert H., and John W. MacArthur. 1961. \"On Bird Species Diversity.\" Ecology 42 (3): 594--98. https://doi.org/10.2307/1932254.</p>"},{"location":"usage/forest-structure/intro/","title":"Introduction","text":"<p>The core forest structural metrics generated by PyForestScan are based on well-established methods in ecology.</p> <p></p> Forest structural metrics as calculated from points within voxels. Voxel resolution is given by \u0394x, \u0394y, \u0394z. <p>Most calculations for the metrics follows the method outlined in Kamoske et al. 2019.</p>"},{"location":"usage/forest-structure/intro/#metrics","title":"Metrics","text":"<ul> <li>Canopy Height Models (CHM)</li> <li>Plant Area Density (PAD)</li> <li>Plant Area Index (PAI)</li> <li>Foliage Height Diversity (FHD)</li> </ul>"},{"location":"usage/forest-structure/intro/#references","title":"References","text":"<p>Kamoske, Aaron G., Kyla M. Dahlin, Scott C. Stark, and Shawn P. Serbin. 2019. \"Leaf Area Density from Airborne LiDAR: Comparing Sensors and Resolutions in a Temperate Broadleaf Forest Ecosystem.\" Forest Ecology and Management 433 (February): 364--75. https://doi.org/10.1016/j.foreco.2018.11.017.</p>"},{"location":"usage/forest-structure/pad/","title":"Plant Area Density (PAD)","text":""},{"location":"usage/forest-structure/pad/#theory","title":"Theory","text":"<p>Plant Area Density (PAD) is a measure of the amount of plant material in a vertical slice of the forest, derived from airborne LiDAR data. The calculation follows the method outlined in Kamoske et al. 2019.</p> \\[PAD_{i-1,i} = \\ln\\left(\\frac{S_e}{S_t}\\right) \\frac{1}{k \\Delta z}\\] <p>Where:</p> <ul> <li><code>PAD_{i-1,i}</code> represents the Plant Area Density between two adjacent     voxels, indexed by ( i-1 ) and ( i ).</li> <li>( S_e ) is the number of lidar pulses entering the voxel.</li> <li>( S_t ) is the number of lidar pulses exiting the voxel.</li> <li>( k ) is the extinction coefficient from the Beer-Lambert Law.</li> <li>( Delta z ) is the height of each voxel.</li> </ul> <p>The equation calculates the natural logarithm of the ratio of entering and exiting lidar pulses, scaled by the inverse of the extinction coefficient and the voxel height. This quantifies the density of plant material between the two voxels.</p>"},{"location":"usage/forest-structure/pad/#calculating-pad","title":"Calculating PAD","text":"<p>To calculate PAD:</p> <pre><code>from pyforestscan.handlers import read_lidar\nfrom pyforestscan.visualize import plot_pad\nfrom pyforestscan.filters import filter_hag\nfrom pyforestscan.calculate import assign_voxels, calculate_pad\n\nfile_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\narrays = filter_hag(arrays)\npoints = arrays[0]\n\nvoxel_resolution = (5, 5, 1) \nvoxels, extent = assign_voxels(points, voxel_resolution)\n\npad = calculate_pad(voxels, voxel_resolution[-1])\nplot_pad(pad, 5, axis='y', cmap='viridis')\n</code></pre> <p></p>"},{"location":"usage/forest-structure/pad/#references","title":"References","text":"<p>Kamoske, Aaron G., Kyla M. Dahlin, Scott C. Stark, and Shawn P. Serbin. 2019. \"Leaf Area Density from Airborne LiDAR: Comparing Sensors and Resolutions in a Temperate Broadleaf Forest Ecosystem.\" Forest Ecology and Management 433 (February): 364--75. https://doi.org/10.1016/j.foreco.2018.11.017.</p>"},{"location":"usage/forest-structure/pai/","title":"Plant Area Index (PAI)","text":""},{"location":"usage/forest-structure/pai/#theory","title":"Theory","text":"<p>Plant Area Index (PAI) is a measure of the total plant material in a vertical column of the forest. It is calculated as the sum of the Plant Area Density (PAD) across all layers in the canopy.</p> \\[ PAI = \\sum_{i=1}^{n} PAD_{i-1,i} \\] <p>Where: -   \\( PAI \\) is the Plant Area Index. -   \\( PAD_{i-1,i} \\) is the Plant Area Density between adjacent layers \\( i-1 \\) and \\( i \\). -   \\( n \\) is the total number of layers in the vertical column.</p> <p>PAI provides an aggregated view of plant material from the ground to the top of the canopy by summing the PAD for each vertical layer.</p>"},{"location":"usage/forest-structure/pai/#calculating-pai","title":"Calculating PAI","text":"<p>To calculate PAI, first calculate PAD, then:</p> <pre><code>from pyforestscan.handlers import read_lidar\nfrom pyforestscan.visualize import plot_metric\nfrom pyforestscan.filters import filter_hag\nfrom pyforestscan.calculate import assign_voxels, calculate_pad, calculate_pai\n\nfile_path = \"../example_data/20191210_5QKB020880.laz\"\narrays = read_lidar(file_path, \"EPSG:32605\", hag=True)\narrays = filter_hag(arrays)\npoints = arrays[0]\n\nvoxel_resolution = (5, 5, 1) \nvoxels, extent = assign_voxels(points, voxel_resolution)\n\npad = calculate_pad(voxels, voxel_resolution[-1])\npai = calculate_pai(pad)\nplot_metric('Plant Area Index', pai, extent, metric_name='PAI', cmap='viridis', fig_size=None)\n</code></pre> <p></p>"}]}